{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTCNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZFIuW0AwB6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwb1191FG9MZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3LKzsQqG9TJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1wHNxZZwDPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training settings\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqZMMNLTwDRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST Dataset\n",
        "train_dataset = datasets.MNIST(root='./data/',\n",
        "                               train=True, # represents the training section of the data\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR5O1PxjwDTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = datasets.MNIST(root='./data/',\n",
        "                              train=False, #validation set \n",
        "                              transform=transforms.ToTensor())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsKKdiiUwDV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jbt773AwDYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4mMI3PtwDaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        '''\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size)\n",
        "        in_channels - number of channels of the input\n",
        "                    - for greyscale images we have 1, or basically a single channel\n",
        "                    - for RGB images we have 3 channels and for sattelite date number can be higher.\n",
        "        \n",
        "        out_channels - number of different filters applied to the input images and the resulting images from the operation\n",
        "                     - in our case is 10 at first conv, so we will have 10 different images as a result of filters applied\n",
        "        '''\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.mp = nn.MaxPool2d(2) # apply max pool with a window of 2X2\n",
        "        self.fc = nn.Linear(320, 10) # final fully-connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        in_size = x.size(0)\n",
        "        x = F.relu(self.mp(self.conv1(x)))\n",
        "        x = F.relu(self.mp(self.conv2(x)))\n",
        "        x = x.view(in_size, -1)  # flatten the tensor\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vv0tT8-wDdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG06UKu0pbh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8LdSz6GwDfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PYHJzLYklej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = []\n",
        "validation_loss=[]\n",
        "validation_accuracy=[]\n",
        "train_accuracy=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClMNkLJ-wDh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    losses=[]\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        losses.append(loss.item())\n",
        "        optimizer.step()\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "    train_loss.append(sum(losses)/len(losses))\n",
        "    train_accuracy.append(correct* 100./len(train_loader.dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCbMimPrwDkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    losses=[]\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            # sum up batch loss\n",
        "            loss= criterion(output, target)\n",
        "            losses.append(loss.item())\n",
        "            # get the index of the max log-probability\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "        test_loss = sum(losses)/len(losses)\n",
        "        validation_loss.append(test_loss)\n",
        "        validation_accuracy.append(100. * correct/len(test_loader.dataset))\n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset),\n",
        "            100. * correct / len(test_loader.dataset)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpBnPL7nwDml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1, 10):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AziL9_J8wDot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#matplotlib este folosit pentru a realiza grafice\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu7UOq8pwDrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Printăm comparativ cu roșu loss-ul de pe setul de validare și cu albastru loss-ul de pe setul de validare.\n",
        "plt.plot(train_loss, \"r-\", validation_loss, \"b-\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baL2AuaswDuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_accuracy, \"r-\", validation_accuracy, \"b-\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1F7e__CwDxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxi7_q4jwDyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJFHXDSywD1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uh2VFMiwD4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0jpVccjwD6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki4s1GKQwD8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}