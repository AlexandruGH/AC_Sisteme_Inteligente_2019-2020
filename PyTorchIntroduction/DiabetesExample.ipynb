{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DiabetesExample.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnVLqgJPKZYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn, from_numpy, optim\n",
        "import numpy as np\n",
        "#pandas- librărie pentru lucrul cu fișierele\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoINPLfdmvGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(\"/content/diabetes.csv\",header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGjK2mEym5gP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "8f7406f8-d723-48e5-f7c0-d52b520cf363"
      },
      "source": [
        "df.values"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.294118 ,  0.487437 ,  0.180328 , ..., -0.53117  , -0.0333333,\n",
              "         0.       ],\n",
              "       [-0.882353 , -0.145729 ,  0.0819672, ..., -0.766866 , -0.666667 ,\n",
              "         1.       ],\n",
              "       [-0.0588235,  0.839196 ,  0.0491803, ..., -0.492741 , -0.633333 ,\n",
              "         0.       ],\n",
              "       ...,\n",
              "       [-0.411765 ,  0.21608  ,  0.180328 , ..., -0.857387 , -0.7      ,\n",
              "         1.       ],\n",
              "       [-0.882353 ,  0.266332 , -0.0163934, ..., -0.768574 , -0.133333 ,\n",
              "         0.       ],\n",
              "       [-0.882353 , -0.0653266,  0.147541 , ..., -0.797609 , -0.933333 ,\n",
              "         1.       ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVMR_ijqKj-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dataset - o clasă din PyTorch foarte utilă gestionării seturilor de date\n",
        "class DiabetesDataset(Dataset):\n",
        "    \"\"\" Diabetes dataset.\"\"\"\n",
        "    # Initialize your data, download, etc.\n",
        "    def __init__(self):\n",
        "        #Citim setul de date\n",
        "        df=pd.read_csv(\"/content/diabetes.csv\",header=None, dtype=np.float32)\n",
        "        xy = torch.from_numpy(df.values)\n",
        "        self.len = xy.shape[0]\n",
        "        #Vom folosi ca input toate valorile mai puțin ultima coloană\n",
        "        self.x_data = xy[:, 0:-1]\n",
        "        #Vom folosi ca output ultima coloană\n",
        "        self.y_data = xy[:, [-1]]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVWrVEUMKkBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = DiabetesDataset()\n",
        "#DataLoader - un utilitar ce ne ajută să împărțim setul de date pe batch-uri și astfel să facem antrenare în mod Mini-Batch\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=32,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44aFZMd_KkC_",
        "colab_type": "code",
        "outputId": "e5f29786-c548-4047-b8ba-d6a15affb162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "dataset[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.2941,  0.4874,  0.1803, -0.2929,  0.0000,  0.0015, -0.5312, -0.0333]),\n",
              " tensor([0.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07jL_JLEKkF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate two nn.Linear module\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "        self.l1 = nn.Linear(8, 6)\n",
        "        self.l2 = nn.Linear(6, 4)\n",
        "        self.l3 = nn.Linear(4, 1)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Variable of input data and we must return\n",
        "        a Variable of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Variables.\n",
        "        \"\"\"\n",
        "        out1 = self.sigmoid(self.l1(x))\n",
        "        out2 = self.sigmoid(self.l2(out1))\n",
        "        y_pred = self.sigmoid(self.l3(out2))\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWeFa6ZzKkH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHWknpAvKkKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss(reduction='sum')\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THRIbzCKKkNI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b23036f9-64d0-453f-ea36-9153fec9e99d"
      },
      "source": [
        "# Training loop\n",
        "for epoch in range(200):\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "      # get the inputs\n",
        "      inputs, labels = data\n",
        "\n",
        "      # Forward pass: Compute predicted y by passing x to the model\n",
        "      y_pred = model(inputs)\n",
        "\n",
        "      # Compute and print loss\n",
        "      loss = criterion(y_pred, labels)\n",
        "      print(f'Epoch {epoch + 1} | Batch: {i+1} | Loss: {loss.item():.4f}')\n",
        "\n",
        "      # Zero gradients, perform a backward pass, and update the weights.\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | Batch: 1 | Loss: 20.2431\n",
            "Epoch 1 | Batch: 2 | Loss: 23.4692\n",
            "Epoch 1 | Batch: 3 | Loss: 20.1881\n",
            "Epoch 1 | Batch: 4 | Loss: 19.0309\n",
            "Epoch 1 | Batch: 5 | Loss: 20.8728\n",
            "Epoch 1 | Batch: 6 | Loss: 20.1789\n",
            "Epoch 1 | Batch: 7 | Loss: 20.9373\n",
            "Epoch 1 | Batch: 8 | Loss: 18.7460\n",
            "Epoch 1 | Batch: 9 | Loss: 28.4625\n",
            "Epoch 1 | Batch: 10 | Loss: 23.3944\n",
            "Epoch 1 | Batch: 11 | Loss: 23.6523\n",
            "Epoch 1 | Batch: 12 | Loss: 23.0491\n",
            "Epoch 1 | Batch: 13 | Loss: 22.4534\n",
            "Epoch 1 | Batch: 14 | Loss: 21.5691\n",
            "Epoch 1 | Batch: 15 | Loss: 21.2487\n",
            "Epoch 1 | Batch: 16 | Loss: 21.6450\n",
            "Epoch 1 | Batch: 17 | Loss: 21.6213\n",
            "Epoch 1 | Batch: 18 | Loss: 19.2690\n",
            "Epoch 1 | Batch: 19 | Loss: 18.4667\n",
            "Epoch 1 | Batch: 20 | Loss: 23.3777\n",
            "Epoch 1 | Batch: 21 | Loss: 21.9526\n",
            "Epoch 1 | Batch: 22 | Loss: 21.9277\n",
            "Epoch 1 | Batch: 23 | Loss: 20.5190\n",
            "Epoch 1 | Batch: 24 | Loss: 14.7283\n",
            "Epoch 2 | Batch: 1 | Loss: 16.2554\n",
            "Epoch 2 | Batch: 2 | Loss: 21.4032\n",
            "Epoch 2 | Batch: 3 | Loss: 19.1647\n",
            "Epoch 2 | Batch: 4 | Loss: 22.9477\n",
            "Epoch 2 | Batch: 5 | Loss: 20.5687\n",
            "Epoch 2 | Batch: 6 | Loss: 24.5285\n",
            "Epoch 2 | Batch: 7 | Loss: 21.4736\n",
            "Epoch 2 | Batch: 8 | Loss: 19.4358\n",
            "Epoch 2 | Batch: 9 | Loss: 16.0418\n",
            "Epoch 2 | Batch: 10 | Loss: 22.6944\n",
            "Epoch 2 | Batch: 11 | Loss: 26.5766\n",
            "Epoch 2 | Batch: 12 | Loss: 30.1520\n",
            "Epoch 2 | Batch: 13 | Loss: 24.2440\n",
            "Epoch 2 | Batch: 14 | Loss: 22.1359\n",
            "Epoch 2 | Batch: 15 | Loss: 20.9061\n",
            "Epoch 2 | Batch: 16 | Loss: 22.4692\n",
            "Epoch 2 | Batch: 17 | Loss: 18.4688\n",
            "Epoch 2 | Batch: 18 | Loss: 22.2680\n",
            "Epoch 2 | Batch: 19 | Loss: 19.0573\n",
            "Epoch 2 | Batch: 20 | Loss: 16.9431\n",
            "Epoch 2 | Batch: 21 | Loss: 23.0069\n",
            "Epoch 2 | Batch: 22 | Loss: 23.3871\n",
            "Epoch 2 | Batch: 23 | Loss: 22.2354\n",
            "Epoch 2 | Batch: 24 | Loss: 15.7474\n",
            "Epoch 3 | Batch: 1 | Loss: 20.0941\n",
            "Epoch 3 | Batch: 2 | Loss: 19.2064\n",
            "Epoch 3 | Batch: 3 | Loss: 21.9407\n",
            "Epoch 3 | Batch: 4 | Loss: 20.6261\n",
            "Epoch 3 | Batch: 5 | Loss: 19.2999\n",
            "Epoch 3 | Batch: 6 | Loss: 20.8366\n",
            "Epoch 3 | Batch: 7 | Loss: 19.9218\n",
            "Epoch 3 | Batch: 8 | Loss: 19.0796\n",
            "Epoch 3 | Batch: 9 | Loss: 22.6942\n",
            "Epoch 3 | Batch: 10 | Loss: 22.4084\n",
            "Epoch 3 | Batch: 11 | Loss: 21.1699\n",
            "Epoch 3 | Batch: 12 | Loss: 25.0407\n",
            "Epoch 3 | Batch: 13 | Loss: 20.3580\n",
            "Epoch 3 | Batch: 14 | Loss: 21.6879\n",
            "Epoch 3 | Batch: 15 | Loss: 20.0996\n",
            "Epoch 3 | Batch: 16 | Loss: 17.5628\n",
            "Epoch 3 | Batch: 17 | Loss: 22.7109\n",
            "Epoch 3 | Batch: 18 | Loss: 20.5909\n",
            "Epoch 3 | Batch: 19 | Loss: 19.2888\n",
            "Epoch 3 | Batch: 20 | Loss: 25.3417\n",
            "Epoch 3 | Batch: 21 | Loss: 22.1753\n",
            "Epoch 3 | Batch: 22 | Loss: 22.1787\n",
            "Epoch 3 | Batch: 23 | Loss: 21.7493\n",
            "Epoch 3 | Batch: 24 | Loss: 14.3990\n",
            "Epoch 4 | Batch: 1 | Loss: 23.4480\n",
            "Epoch 4 | Batch: 2 | Loss: 21.0644\n",
            "Epoch 4 | Batch: 3 | Loss: 21.0071\n",
            "Epoch 4 | Batch: 4 | Loss: 20.5713\n",
            "Epoch 4 | Batch: 5 | Loss: 20.5782\n",
            "Epoch 4 | Batch: 6 | Loss: 23.1675\n",
            "Epoch 4 | Batch: 7 | Loss: 21.8145\n",
            "Epoch 4 | Batch: 8 | Loss: 19.3775\n",
            "Epoch 4 | Batch: 9 | Loss: 28.0788\n",
            "Epoch 4 | Batch: 10 | Loss: 22.2347\n",
            "Epoch 4 | Batch: 11 | Loss: 21.7924\n",
            "Epoch 4 | Batch: 12 | Loss: 21.2082\n",
            "Epoch 4 | Batch: 13 | Loss: 21.1599\n",
            "Epoch 4 | Batch: 14 | Loss: 19.6350\n",
            "Epoch 4 | Batch: 15 | Loss: 19.0098\n",
            "Epoch 4 | Batch: 16 | Loss: 15.2870\n",
            "Epoch 4 | Batch: 17 | Loss: 25.4374\n",
            "Epoch 4 | Batch: 18 | Loss: 20.0032\n",
            "Epoch 4 | Batch: 19 | Loss: 20.6180\n",
            "Epoch 4 | Batch: 20 | Loss: 21.8966\n",
            "Epoch 4 | Batch: 21 | Loss: 20.7813\n",
            "Epoch 4 | Batch: 22 | Loss: 17.4767\n",
            "Epoch 4 | Batch: 23 | Loss: 20.5140\n",
            "Epoch 4 | Batch: 24 | Loss: 16.8203\n",
            "Epoch 5 | Batch: 1 | Loss: 21.6553\n",
            "Epoch 5 | Batch: 2 | Loss: 21.9822\n",
            "Epoch 5 | Batch: 3 | Loss: 22.1807\n",
            "Epoch 5 | Batch: 4 | Loss: 21.5491\n",
            "Epoch 5 | Batch: 5 | Loss: 18.7782\n",
            "Epoch 5 | Batch: 6 | Loss: 18.0201\n",
            "Epoch 5 | Batch: 7 | Loss: 23.3310\n",
            "Epoch 5 | Batch: 8 | Loss: 20.6656\n",
            "Epoch 5 | Batch: 9 | Loss: 18.0668\n",
            "Epoch 5 | Batch: 10 | Loss: 23.5857\n",
            "Epoch 5 | Batch: 11 | Loss: 20.1274\n",
            "Epoch 5 | Batch: 12 | Loss: 20.6046\n",
            "Epoch 5 | Batch: 13 | Loss: 23.2230\n",
            "Epoch 5 | Batch: 14 | Loss: 20.5038\n",
            "Epoch 5 | Batch: 15 | Loss: 21.5582\n",
            "Epoch 5 | Batch: 16 | Loss: 21.3457\n",
            "Epoch 5 | Batch: 17 | Loss: 21.7007\n",
            "Epoch 5 | Batch: 18 | Loss: 19.5686\n",
            "Epoch 5 | Batch: 19 | Loss: 24.7667\n",
            "Epoch 5 | Batch: 20 | Loss: 20.4511\n",
            "Epoch 5 | Batch: 21 | Loss: 21.7933\n",
            "Epoch 5 | Batch: 22 | Loss: 19.9938\n",
            "Epoch 5 | Batch: 23 | Loss: 21.3262\n",
            "Epoch 5 | Batch: 24 | Loss: 14.2894\n",
            "Epoch 6 | Batch: 1 | Loss: 20.5513\n",
            "Epoch 6 | Batch: 2 | Loss: 20.5410\n",
            "Epoch 6 | Batch: 3 | Loss: 17.9578\n",
            "Epoch 6 | Batch: 4 | Loss: 25.7459\n",
            "Epoch 6 | Batch: 5 | Loss: 21.0551\n",
            "Epoch 6 | Batch: 6 | Loss: 18.1435\n",
            "Epoch 6 | Batch: 7 | Loss: 21.2778\n",
            "Epoch 6 | Batch: 8 | Loss: 22.8410\n",
            "Epoch 6 | Batch: 9 | Loss: 21.2745\n",
            "Epoch 6 | Batch: 10 | Loss: 20.1739\n",
            "Epoch 6 | Batch: 11 | Loss: 22.0474\n",
            "Epoch 6 | Batch: 12 | Loss: 21.6095\n",
            "Epoch 6 | Batch: 13 | Loss: 21.5514\n",
            "Epoch 6 | Batch: 14 | Loss: 22.7122\n",
            "Epoch 6 | Batch: 15 | Loss: 21.9325\n",
            "Epoch 6 | Batch: 16 | Loss: 19.3840\n",
            "Epoch 6 | Batch: 17 | Loss: 20.6819\n",
            "Epoch 6 | Batch: 18 | Loss: 21.2364\n",
            "Epoch 6 | Batch: 19 | Loss: 21.6276\n",
            "Epoch 6 | Batch: 20 | Loss: 20.3426\n",
            "Epoch 6 | Batch: 21 | Loss: 19.7969\n",
            "Epoch 6 | Batch: 22 | Loss: 15.8513\n",
            "Epoch 6 | Batch: 23 | Loss: 20.9463\n",
            "Epoch 6 | Batch: 24 | Loss: 15.0286\n",
            "Epoch 7 | Batch: 1 | Loss: 18.2344\n",
            "Epoch 7 | Batch: 2 | Loss: 24.0109\n",
            "Epoch 7 | Batch: 3 | Loss: 20.0510\n",
            "Epoch 7 | Batch: 4 | Loss: 21.4200\n",
            "Epoch 7 | Batch: 5 | Loss: 21.0760\n",
            "Epoch 7 | Batch: 6 | Loss: 20.0073\n",
            "Epoch 7 | Batch: 7 | Loss: 18.3068\n",
            "Epoch 7 | Batch: 8 | Loss: 21.9706\n",
            "Epoch 7 | Batch: 9 | Loss: 18.6417\n",
            "Epoch 7 | Batch: 10 | Loss: 24.7145\n",
            "Epoch 7 | Batch: 11 | Loss: 22.0828\n",
            "Epoch 7 | Batch: 12 | Loss: 21.5987\n",
            "Epoch 7 | Batch: 13 | Loss: 21.5300\n",
            "Epoch 7 | Batch: 14 | Loss: 21.0477\n",
            "Epoch 7 | Batch: 15 | Loss: 20.4980\n",
            "Epoch 7 | Batch: 16 | Loss: 20.5166\n",
            "Epoch 7 | Batch: 17 | Loss: 22.9761\n",
            "Epoch 7 | Batch: 18 | Loss: 21.2683\n",
            "Epoch 7 | Batch: 19 | Loss: 18.6995\n",
            "Epoch 7 | Batch: 20 | Loss: 21.8062\n",
            "Epoch 7 | Batch: 21 | Loss: 18.6731\n",
            "Epoch 7 | Batch: 22 | Loss: 20.8444\n",
            "Epoch 7 | Batch: 23 | Loss: 19.7459\n",
            "Epoch 7 | Batch: 24 | Loss: 13.1761\n",
            "Epoch 8 | Batch: 1 | Loss: 23.4614\n",
            "Epoch 8 | Batch: 2 | Loss: 19.6779\n",
            "Epoch 8 | Batch: 3 | Loss: 12.9910\n",
            "Epoch 8 | Batch: 4 | Loss: 15.3154\n",
            "Epoch 8 | Batch: 5 | Loss: 23.0512\n",
            "Epoch 8 | Batch: 6 | Loss: 23.8550\n",
            "Epoch 8 | Batch: 7 | Loss: 21.2530\n",
            "Epoch 8 | Batch: 8 | Loss: 19.9966\n",
            "Epoch 8 | Batch: 9 | Loss: 21.8495\n",
            "Epoch 8 | Batch: 10 | Loss: 19.7365\n",
            "Epoch 8 | Batch: 11 | Loss: 21.3191\n",
            "Epoch 8 | Batch: 12 | Loss: 21.8942\n",
            "Epoch 8 | Batch: 13 | Loss: 20.2379\n",
            "Epoch 8 | Batch: 14 | Loss: 19.3260\n",
            "Epoch 8 | Batch: 15 | Loss: 24.1324\n",
            "Epoch 8 | Batch: 16 | Loss: 21.0886\n",
            "Epoch 8 | Batch: 17 | Loss: 18.8940\n",
            "Epoch 8 | Batch: 18 | Loss: 22.5378\n",
            "Epoch 8 | Batch: 19 | Loss: 21.1268\n",
            "Epoch 8 | Batch: 20 | Loss: 22.0408\n",
            "Epoch 8 | Batch: 21 | Loss: 21.4744\n",
            "Epoch 8 | Batch: 22 | Loss: 19.1637\n",
            "Epoch 8 | Batch: 23 | Loss: 32.2980\n",
            "Epoch 8 | Batch: 24 | Loss: 16.9004\n",
            "Epoch 9 | Batch: 1 | Loss: 18.0364\n",
            "Epoch 9 | Batch: 2 | Loss: 22.2512\n",
            "Epoch 9 | Batch: 3 | Loss: 18.9530\n",
            "Epoch 9 | Batch: 4 | Loss: 20.3055\n",
            "Epoch 9 | Batch: 5 | Loss: 16.4909\n",
            "Epoch 9 | Batch: 6 | Loss: 23.8247\n",
            "Epoch 9 | Batch: 7 | Loss: 17.5411\n",
            "Epoch 9 | Batch: 8 | Loss: 22.1484\n",
            "Epoch 9 | Batch: 9 | Loss: 21.4531\n",
            "Epoch 9 | Batch: 10 | Loss: 21.2457\n",
            "Epoch 9 | Batch: 11 | Loss: 20.1831\n",
            "Epoch 9 | Batch: 12 | Loss: 20.0144\n",
            "Epoch 9 | Batch: 13 | Loss: 23.0133\n",
            "Epoch 9 | Batch: 14 | Loss: 20.7711\n",
            "Epoch 9 | Batch: 15 | Loss: 20.8066\n",
            "Epoch 9 | Batch: 16 | Loss: 19.2543\n",
            "Epoch 9 | Batch: 17 | Loss: 18.8536\n",
            "Epoch 9 | Batch: 18 | Loss: 20.3605\n",
            "Epoch 9 | Batch: 19 | Loss: 18.9279\n",
            "Epoch 9 | Batch: 20 | Loss: 20.2730\n",
            "Epoch 9 | Batch: 21 | Loss: 16.9450\n",
            "Epoch 9 | Batch: 22 | Loss: 19.2156\n",
            "Epoch 9 | Batch: 23 | Loss: 21.6842\n",
            "Epoch 9 | Batch: 24 | Loss: 15.1848\n",
            "Epoch 10 | Batch: 1 | Loss: 20.2643\n",
            "Epoch 10 | Batch: 2 | Loss: 18.9771\n",
            "Epoch 10 | Batch: 3 | Loss: 18.5371\n",
            "Epoch 10 | Batch: 4 | Loss: 19.6081\n",
            "Epoch 10 | Batch: 5 | Loss: 18.5407\n",
            "Epoch 10 | Batch: 6 | Loss: 16.7420\n",
            "Epoch 10 | Batch: 7 | Loss: 27.2212\n",
            "Epoch 10 | Batch: 8 | Loss: 23.0977\n",
            "Epoch 10 | Batch: 9 | Loss: 21.9737\n",
            "Epoch 10 | Batch: 10 | Loss: 20.5619\n",
            "Epoch 10 | Batch: 11 | Loss: 20.6010\n",
            "Epoch 10 | Batch: 12 | Loss: 19.7197\n",
            "Epoch 10 | Batch: 13 | Loss: 17.3875\n",
            "Epoch 10 | Batch: 14 | Loss: 16.3870\n",
            "Epoch 10 | Batch: 15 | Loss: 17.8377\n",
            "Epoch 10 | Batch: 16 | Loss: 14.3277\n",
            "Epoch 10 | Batch: 17 | Loss: 16.6284\n",
            "Epoch 10 | Batch: 18 | Loss: 18.1641\n",
            "Epoch 10 | Batch: 19 | Loss: 22.2050\n",
            "Epoch 10 | Batch: 20 | Loss: 19.1179\n",
            "Epoch 10 | Batch: 21 | Loss: 18.9244\n",
            "Epoch 10 | Batch: 22 | Loss: 21.6733\n",
            "Epoch 10 | Batch: 23 | Loss: 20.9155\n",
            "Epoch 10 | Batch: 24 | Loss: 13.3581\n",
            "Epoch 11 | Batch: 1 | Loss: 16.0575\n",
            "Epoch 11 | Batch: 2 | Loss: 15.0811\n",
            "Epoch 11 | Batch: 3 | Loss: 16.0969\n",
            "Epoch 11 | Batch: 4 | Loss: 13.3390\n",
            "Epoch 11 | Batch: 5 | Loss: 16.5716\n",
            "Epoch 11 | Batch: 6 | Loss: 19.3171\n",
            "Epoch 11 | Batch: 7 | Loss: 18.1646\n",
            "Epoch 11 | Batch: 8 | Loss: 15.5705\n",
            "Epoch 11 | Batch: 9 | Loss: 15.7626\n",
            "Epoch 11 | Batch: 10 | Loss: 16.4357\n",
            "Epoch 11 | Batch: 11 | Loss: 17.3137\n",
            "Epoch 11 | Batch: 12 | Loss: 16.8556\n",
            "Epoch 11 | Batch: 13 | Loss: 16.2399\n",
            "Epoch 11 | Batch: 14 | Loss: 18.3237\n",
            "Epoch 11 | Batch: 15 | Loss: 19.0195\n",
            "Epoch 11 | Batch: 16 | Loss: 15.3418\n",
            "Epoch 11 | Batch: 17 | Loss: 20.8767\n",
            "Epoch 11 | Batch: 18 | Loss: 16.1642\n",
            "Epoch 11 | Batch: 19 | Loss: 17.0995\n",
            "Epoch 11 | Batch: 20 | Loss: 14.0962\n",
            "Epoch 11 | Batch: 21 | Loss: 18.3829\n",
            "Epoch 11 | Batch: 22 | Loss: 14.3253\n",
            "Epoch 11 | Batch: 23 | Loss: 17.5468\n",
            "Epoch 11 | Batch: 24 | Loss: 14.4887\n",
            "Epoch 12 | Batch: 1 | Loss: 20.5037\n",
            "Epoch 12 | Batch: 2 | Loss: 14.8161\n",
            "Epoch 12 | Batch: 3 | Loss: 14.4237\n",
            "Epoch 12 | Batch: 4 | Loss: 17.5114\n",
            "Epoch 12 | Batch: 5 | Loss: 16.0802\n",
            "Epoch 12 | Batch: 6 | Loss: 16.2920\n",
            "Epoch 12 | Batch: 7 | Loss: 15.0914\n",
            "Epoch 12 | Batch: 8 | Loss: 12.4145\n",
            "Epoch 12 | Batch: 9 | Loss: 18.8190\n",
            "Epoch 12 | Batch: 10 | Loss: 18.6679\n",
            "Epoch 12 | Batch: 11 | Loss: 17.6154\n",
            "Epoch 12 | Batch: 12 | Loss: 21.4017\n",
            "Epoch 12 | Batch: 13 | Loss: 19.1432\n",
            "Epoch 12 | Batch: 14 | Loss: 20.8211\n",
            "Epoch 12 | Batch: 15 | Loss: 25.7179\n",
            "Epoch 12 | Batch: 16 | Loss: 16.2940\n",
            "Epoch 12 | Batch: 17 | Loss: 13.3869\n",
            "Epoch 12 | Batch: 18 | Loss: 15.6622\n",
            "Epoch 12 | Batch: 19 | Loss: 15.4347\n",
            "Epoch 12 | Batch: 20 | Loss: 17.3672\n",
            "Epoch 12 | Batch: 21 | Loss: 17.3921\n",
            "Epoch 12 | Batch: 22 | Loss: 13.3824\n",
            "Epoch 12 | Batch: 23 | Loss: 16.8748\n",
            "Epoch 12 | Batch: 24 | Loss: 15.8258\n",
            "Epoch 13 | Batch: 1 | Loss: 17.3744\n",
            "Epoch 13 | Batch: 2 | Loss: 28.6724\n",
            "Epoch 13 | Batch: 3 | Loss: 25.7761\n",
            "Epoch 13 | Batch: 4 | Loss: 13.3780\n",
            "Epoch 13 | Batch: 5 | Loss: 8.2801\n",
            "Epoch 13 | Batch: 6 | Loss: 19.2628\n",
            "Epoch 13 | Batch: 7 | Loss: 15.0700\n",
            "Epoch 13 | Batch: 8 | Loss: 13.1378\n",
            "Epoch 13 | Batch: 9 | Loss: 19.3798\n",
            "Epoch 13 | Batch: 10 | Loss: 21.1354\n",
            "Epoch 13 | Batch: 11 | Loss: 17.8587\n",
            "Epoch 13 | Batch: 12 | Loss: 19.4762\n",
            "Epoch 13 | Batch: 13 | Loss: 14.8107\n",
            "Epoch 13 | Batch: 14 | Loss: 17.4563\n",
            "Epoch 13 | Batch: 15 | Loss: 14.6184\n",
            "Epoch 13 | Batch: 16 | Loss: 17.4928\n",
            "Epoch 13 | Batch: 17 | Loss: 13.7060\n",
            "Epoch 13 | Batch: 18 | Loss: 10.8715\n",
            "Epoch 13 | Batch: 19 | Loss: 14.3630\n",
            "Epoch 13 | Batch: 20 | Loss: 12.4077\n",
            "Epoch 13 | Batch: 21 | Loss: 14.4039\n",
            "Epoch 13 | Batch: 22 | Loss: 15.2560\n",
            "Epoch 13 | Batch: 23 | Loss: 21.1339\n",
            "Epoch 13 | Batch: 24 | Loss: 14.1645\n",
            "Epoch 14 | Batch: 1 | Loss: 16.1590\n",
            "Epoch 14 | Batch: 2 | Loss: 16.5336\n",
            "Epoch 14 | Batch: 3 | Loss: 13.3319\n",
            "Epoch 14 | Batch: 4 | Loss: 17.0460\n",
            "Epoch 14 | Batch: 5 | Loss: 17.5803\n",
            "Epoch 14 | Batch: 6 | Loss: 15.0832\n",
            "Epoch 14 | Batch: 7 | Loss: 13.5905\n",
            "Epoch 14 | Batch: 8 | Loss: 16.0267\n",
            "Epoch 14 | Batch: 9 | Loss: 22.6065\n",
            "Epoch 14 | Batch: 10 | Loss: 13.0686\n",
            "Epoch 14 | Batch: 11 | Loss: 16.9421\n",
            "Epoch 14 | Batch: 12 | Loss: 14.0689\n",
            "Epoch 14 | Batch: 13 | Loss: 13.3295\n",
            "Epoch 14 | Batch: 14 | Loss: 18.9995\n",
            "Epoch 14 | Batch: 15 | Loss: 19.6321\n",
            "Epoch 14 | Batch: 16 | Loss: 19.8485\n",
            "Epoch 14 | Batch: 17 | Loss: 17.0228\n",
            "Epoch 14 | Batch: 18 | Loss: 18.8204\n",
            "Epoch 14 | Batch: 19 | Loss: 16.0584\n",
            "Epoch 14 | Batch: 20 | Loss: 15.7275\n",
            "Epoch 14 | Batch: 21 | Loss: 17.2451\n",
            "Epoch 14 | Batch: 22 | Loss: 12.7948\n",
            "Epoch 14 | Batch: 23 | Loss: 13.5122\n",
            "Epoch 14 | Batch: 24 | Loss: 10.4362\n",
            "Epoch 15 | Batch: 1 | Loss: 16.1896\n",
            "Epoch 15 | Batch: 2 | Loss: 14.4684\n",
            "Epoch 15 | Batch: 3 | Loss: 17.9699\n",
            "Epoch 15 | Batch: 4 | Loss: 17.5455\n",
            "Epoch 15 | Batch: 5 | Loss: 17.5714\n",
            "Epoch 15 | Batch: 6 | Loss: 19.0976\n",
            "Epoch 15 | Batch: 7 | Loss: 19.3684\n",
            "Epoch 15 | Batch: 8 | Loss: 18.9604\n",
            "Epoch 15 | Batch: 9 | Loss: 16.2189\n",
            "Epoch 15 | Batch: 10 | Loss: 16.6345\n",
            "Epoch 15 | Batch: 11 | Loss: 13.3679\n",
            "Epoch 15 | Batch: 12 | Loss: 13.5094\n",
            "Epoch 15 | Batch: 13 | Loss: 14.8487\n",
            "Epoch 15 | Batch: 14 | Loss: 15.6338\n",
            "Epoch 15 | Batch: 15 | Loss: 12.9878\n",
            "Epoch 15 | Batch: 16 | Loss: 14.0111\n",
            "Epoch 15 | Batch: 17 | Loss: 17.2371\n",
            "Epoch 15 | Batch: 18 | Loss: 16.8321\n",
            "Epoch 15 | Batch: 19 | Loss: 13.6626\n",
            "Epoch 15 | Batch: 20 | Loss: 10.2695\n",
            "Epoch 15 | Batch: 21 | Loss: 12.6407\n",
            "Epoch 15 | Batch: 22 | Loss: 13.1164\n",
            "Epoch 15 | Batch: 23 | Loss: 11.1635\n",
            "Epoch 15 | Batch: 24 | Loss: 8.9294\n",
            "Epoch 16 | Batch: 1 | Loss: 26.5792\n",
            "Epoch 16 | Batch: 2 | Loss: 19.4766\n",
            "Epoch 16 | Batch: 3 | Loss: 17.5694\n",
            "Epoch 16 | Batch: 4 | Loss: 13.7538\n",
            "Epoch 16 | Batch: 5 | Loss: 14.2629\n",
            "Epoch 16 | Batch: 6 | Loss: 11.6047\n",
            "Epoch 16 | Batch: 7 | Loss: 19.5053\n",
            "Epoch 16 | Batch: 8 | Loss: 14.7493\n",
            "Epoch 16 | Batch: 9 | Loss: 16.3759\n",
            "Epoch 16 | Batch: 10 | Loss: 13.0879\n",
            "Epoch 16 | Batch: 11 | Loss: 16.4496\n",
            "Epoch 16 | Batch: 12 | Loss: 18.0566\n",
            "Epoch 16 | Batch: 13 | Loss: 21.0851\n",
            "Epoch 16 | Batch: 14 | Loss: 15.4109\n",
            "Epoch 16 | Batch: 15 | Loss: 11.3154\n",
            "Epoch 16 | Batch: 16 | Loss: 23.2029\n",
            "Epoch 16 | Batch: 17 | Loss: 15.3164\n",
            "Epoch 16 | Batch: 18 | Loss: 15.7380\n",
            "Epoch 16 | Batch: 19 | Loss: 15.7029\n",
            "Epoch 16 | Batch: 20 | Loss: 17.4987\n",
            "Epoch 16 | Batch: 21 | Loss: 18.4726\n",
            "Epoch 16 | Batch: 22 | Loss: 12.0686\n",
            "Epoch 16 | Batch: 23 | Loss: 17.0748\n",
            "Epoch 16 | Batch: 24 | Loss: 6.8434\n",
            "Epoch 17 | Batch: 1 | Loss: 14.6524\n",
            "Epoch 17 | Batch: 2 | Loss: 14.8171\n",
            "Epoch 17 | Batch: 3 | Loss: 13.2440\n",
            "Epoch 17 | Batch: 4 | Loss: 15.6528\n",
            "Epoch 17 | Batch: 5 | Loss: 14.4012\n",
            "Epoch 17 | Batch: 6 | Loss: 10.3877\n",
            "Epoch 17 | Batch: 7 | Loss: 12.5804\n",
            "Epoch 17 | Batch: 8 | Loss: 11.2585\n",
            "Epoch 17 | Batch: 9 | Loss: 16.9853\n",
            "Epoch 17 | Batch: 10 | Loss: 19.7188\n",
            "Epoch 17 | Batch: 11 | Loss: 20.4423\n",
            "Epoch 17 | Batch: 12 | Loss: 14.1501\n",
            "Epoch 17 | Batch: 13 | Loss: 18.1490\n",
            "Epoch 17 | Batch: 14 | Loss: 14.7152\n",
            "Epoch 17 | Batch: 15 | Loss: 19.1607\n",
            "Epoch 17 | Batch: 16 | Loss: 16.8166\n",
            "Epoch 17 | Batch: 17 | Loss: 15.3633\n",
            "Epoch 17 | Batch: 18 | Loss: 13.5712\n",
            "Epoch 17 | Batch: 19 | Loss: 12.0777\n",
            "Epoch 17 | Batch: 20 | Loss: 15.3123\n",
            "Epoch 17 | Batch: 21 | Loss: 19.5239\n",
            "Epoch 17 | Batch: 22 | Loss: 14.3027\n",
            "Epoch 17 | Batch: 23 | Loss: 16.4340\n",
            "Epoch 17 | Batch: 24 | Loss: 14.8289\n",
            "Epoch 18 | Batch: 1 | Loss: 15.3872\n",
            "Epoch 18 | Batch: 2 | Loss: 24.3070\n",
            "Epoch 18 | Batch: 3 | Loss: 23.4261\n",
            "Epoch 18 | Batch: 4 | Loss: 16.6235\n",
            "Epoch 18 | Batch: 5 | Loss: 16.4490\n",
            "Epoch 18 | Batch: 6 | Loss: 13.1227\n",
            "Epoch 18 | Batch: 7 | Loss: 16.4196\n",
            "Epoch 18 | Batch: 8 | Loss: 15.2500\n",
            "Epoch 18 | Batch: 9 | Loss: 22.1394\n",
            "Epoch 18 | Batch: 10 | Loss: 12.9610\n",
            "Epoch 18 | Batch: 11 | Loss: 15.6835\n",
            "Epoch 18 | Batch: 12 | Loss: 11.5254\n",
            "Epoch 18 | Batch: 13 | Loss: 13.8249\n",
            "Epoch 18 | Batch: 14 | Loss: 18.5741\n",
            "Epoch 18 | Batch: 15 | Loss: 14.2692\n",
            "Epoch 18 | Batch: 16 | Loss: 17.4959\n",
            "Epoch 18 | Batch: 17 | Loss: 16.2346\n",
            "Epoch 18 | Batch: 18 | Loss: 11.8152\n",
            "Epoch 18 | Batch: 19 | Loss: 24.3827\n",
            "Epoch 18 | Batch: 20 | Loss: 19.5265\n",
            "Epoch 18 | Batch: 21 | Loss: 16.0789\n",
            "Epoch 18 | Batch: 22 | Loss: 14.7870\n",
            "Epoch 18 | Batch: 23 | Loss: 13.2660\n",
            "Epoch 18 | Batch: 24 | Loss: 11.0222\n",
            "Epoch 19 | Batch: 1 | Loss: 11.1061\n",
            "Epoch 19 | Batch: 2 | Loss: 13.8399\n",
            "Epoch 19 | Batch: 3 | Loss: 13.8528\n",
            "Epoch 19 | Batch: 4 | Loss: 16.6453\n",
            "Epoch 19 | Batch: 5 | Loss: 15.8551\n",
            "Epoch 19 | Batch: 6 | Loss: 13.9462\n",
            "Epoch 19 | Batch: 7 | Loss: 13.4793\n",
            "Epoch 19 | Batch: 8 | Loss: 17.9098\n",
            "Epoch 19 | Batch: 9 | Loss: 18.3240\n",
            "Epoch 19 | Batch: 10 | Loss: 11.6715\n",
            "Epoch 19 | Batch: 11 | Loss: 14.6068\n",
            "Epoch 19 | Batch: 12 | Loss: 18.9175\n",
            "Epoch 19 | Batch: 13 | Loss: 14.4891\n",
            "Epoch 19 | Batch: 14 | Loss: 14.4436\n",
            "Epoch 19 | Batch: 15 | Loss: 14.3254\n",
            "Epoch 19 | Batch: 16 | Loss: 16.8413\n",
            "Epoch 19 | Batch: 17 | Loss: 16.1423\n",
            "Epoch 19 | Batch: 18 | Loss: 16.9771\n",
            "Epoch 19 | Batch: 19 | Loss: 15.8987\n",
            "Epoch 19 | Batch: 20 | Loss: 14.9447\n",
            "Epoch 19 | Batch: 21 | Loss: 18.5872\n",
            "Epoch 19 | Batch: 22 | Loss: 15.4120\n",
            "Epoch 19 | Batch: 23 | Loss: 14.6424\n",
            "Epoch 19 | Batch: 24 | Loss: 11.1281\n",
            "Epoch 20 | Batch: 1 | Loss: 17.5517\n",
            "Epoch 20 | Batch: 2 | Loss: 16.6652\n",
            "Epoch 20 | Batch: 3 | Loss: 11.6622\n",
            "Epoch 20 | Batch: 4 | Loss: 15.0475\n",
            "Epoch 20 | Batch: 5 | Loss: 16.5543\n",
            "Epoch 20 | Batch: 6 | Loss: 17.4970\n",
            "Epoch 20 | Batch: 7 | Loss: 11.7740\n",
            "Epoch 20 | Batch: 8 | Loss: 11.4332\n",
            "Epoch 20 | Batch: 9 | Loss: 15.7052\n",
            "Epoch 20 | Batch: 10 | Loss: 18.0174\n",
            "Epoch 20 | Batch: 11 | Loss: 18.8776\n",
            "Epoch 20 | Batch: 12 | Loss: 12.8763\n",
            "Epoch 20 | Batch: 13 | Loss: 13.4581\n",
            "Epoch 20 | Batch: 14 | Loss: 16.0102\n",
            "Epoch 20 | Batch: 15 | Loss: 17.3277\n",
            "Epoch 20 | Batch: 16 | Loss: 16.3613\n",
            "Epoch 20 | Batch: 17 | Loss: 14.1524\n",
            "Epoch 20 | Batch: 18 | Loss: 11.4246\n",
            "Epoch 20 | Batch: 19 | Loss: 19.8228\n",
            "Epoch 20 | Batch: 20 | Loss: 15.8136\n",
            "Epoch 20 | Batch: 21 | Loss: 11.6645\n",
            "Epoch 20 | Batch: 22 | Loss: 18.1848\n",
            "Epoch 20 | Batch: 23 | Loss: 14.0115\n",
            "Epoch 20 | Batch: 24 | Loss: 10.5664\n",
            "Epoch 21 | Batch: 1 | Loss: 13.8679\n",
            "Epoch 21 | Batch: 2 | Loss: 16.0287\n",
            "Epoch 21 | Batch: 3 | Loss: 17.4719\n",
            "Epoch 21 | Batch: 4 | Loss: 8.7563\n",
            "Epoch 21 | Batch: 5 | Loss: 16.3091\n",
            "Epoch 21 | Batch: 6 | Loss: 12.3868\n",
            "Epoch 21 | Batch: 7 | Loss: 18.8924\n",
            "Epoch 21 | Batch: 8 | Loss: 17.9809\n",
            "Epoch 21 | Batch: 9 | Loss: 14.9863\n",
            "Epoch 21 | Batch: 10 | Loss: 12.3875\n",
            "Epoch 21 | Batch: 11 | Loss: 16.1876\n",
            "Epoch 21 | Batch: 12 | Loss: 15.8688\n",
            "Epoch 21 | Batch: 13 | Loss: 16.9716\n",
            "Epoch 21 | Batch: 14 | Loss: 17.2586\n",
            "Epoch 21 | Batch: 15 | Loss: 14.0883\n",
            "Epoch 21 | Batch: 16 | Loss: 22.0492\n",
            "Epoch 21 | Batch: 17 | Loss: 24.7190\n",
            "Epoch 21 | Batch: 18 | Loss: 13.2031\n",
            "Epoch 21 | Batch: 19 | Loss: 11.4915\n",
            "Epoch 21 | Batch: 20 | Loss: 15.5403\n",
            "Epoch 21 | Batch: 21 | Loss: 15.5887\n",
            "Epoch 21 | Batch: 22 | Loss: 15.2586\n",
            "Epoch 21 | Batch: 23 | Loss: 15.0461\n",
            "Epoch 21 | Batch: 24 | Loss: 10.0725\n",
            "Epoch 22 | Batch: 1 | Loss: 21.0821\n",
            "Epoch 22 | Batch: 2 | Loss: 20.5642\n",
            "Epoch 22 | Batch: 3 | Loss: 13.4693\n",
            "Epoch 22 | Batch: 4 | Loss: 16.6322\n",
            "Epoch 22 | Batch: 5 | Loss: 18.0188\n",
            "Epoch 22 | Batch: 6 | Loss: 14.4644\n",
            "Epoch 22 | Batch: 7 | Loss: 15.8047\n",
            "Epoch 22 | Batch: 8 | Loss: 12.1584\n",
            "Epoch 22 | Batch: 9 | Loss: 18.9137\n",
            "Epoch 22 | Batch: 10 | Loss: 14.4315\n",
            "Epoch 22 | Batch: 11 | Loss: 16.6838\n",
            "Epoch 22 | Batch: 12 | Loss: 17.6213\n",
            "Epoch 22 | Batch: 13 | Loss: 15.6134\n",
            "Epoch 22 | Batch: 14 | Loss: 18.0763\n",
            "Epoch 22 | Batch: 15 | Loss: 13.5124\n",
            "Epoch 22 | Batch: 16 | Loss: 18.7984\n",
            "Epoch 22 | Batch: 17 | Loss: 13.7827\n",
            "Epoch 22 | Batch: 18 | Loss: 11.8531\n",
            "Epoch 22 | Batch: 19 | Loss: 17.2111\n",
            "Epoch 22 | Batch: 20 | Loss: 15.4796\n",
            "Epoch 22 | Batch: 21 | Loss: 13.4749\n",
            "Epoch 22 | Batch: 22 | Loss: 9.0414\n",
            "Epoch 22 | Batch: 23 | Loss: 16.6267\n",
            "Epoch 22 | Batch: 24 | Loss: 7.4473\n",
            "Epoch 23 | Batch: 1 | Loss: 17.0515\n",
            "Epoch 23 | Batch: 2 | Loss: 19.8667\n",
            "Epoch 23 | Batch: 3 | Loss: 11.8091\n",
            "Epoch 23 | Batch: 4 | Loss: 14.9566\n",
            "Epoch 23 | Batch: 5 | Loss: 14.6208\n",
            "Epoch 23 | Batch: 6 | Loss: 14.1961\n",
            "Epoch 23 | Batch: 7 | Loss: 12.3061\n",
            "Epoch 23 | Batch: 8 | Loss: 18.1443\n",
            "Epoch 23 | Batch: 9 | Loss: 14.2100\n",
            "Epoch 23 | Batch: 10 | Loss: 16.9399\n",
            "Epoch 23 | Batch: 11 | Loss: 14.3256\n",
            "Epoch 23 | Batch: 12 | Loss: 25.3345\n",
            "Epoch 23 | Batch: 13 | Loss: 21.6123\n",
            "Epoch 23 | Batch: 14 | Loss: 14.1639\n",
            "Epoch 23 | Batch: 15 | Loss: 12.2197\n",
            "Epoch 23 | Batch: 16 | Loss: 14.9294\n",
            "Epoch 23 | Batch: 17 | Loss: 14.8177\n",
            "Epoch 23 | Batch: 18 | Loss: 16.7588\n",
            "Epoch 23 | Batch: 19 | Loss: 20.0961\n",
            "Epoch 23 | Batch: 20 | Loss: 9.2594\n",
            "Epoch 23 | Batch: 21 | Loss: 17.3405\n",
            "Epoch 23 | Batch: 22 | Loss: 16.5639\n",
            "Epoch 23 | Batch: 23 | Loss: 17.5176\n",
            "Epoch 23 | Batch: 24 | Loss: 9.6208\n",
            "Epoch 24 | Batch: 1 | Loss: 20.7364\n",
            "Epoch 24 | Batch: 2 | Loss: 16.0260\n",
            "Epoch 24 | Batch: 3 | Loss: 19.1124\n",
            "Epoch 24 | Batch: 4 | Loss: 14.0004\n",
            "Epoch 24 | Batch: 5 | Loss: 16.6597\n",
            "Epoch 24 | Batch: 6 | Loss: 14.1714\n",
            "Epoch 24 | Batch: 7 | Loss: 14.7246\n",
            "Epoch 24 | Batch: 8 | Loss: 15.5353\n",
            "Epoch 24 | Batch: 9 | Loss: 17.6612\n",
            "Epoch 24 | Batch: 10 | Loss: 19.7257\n",
            "Epoch 24 | Batch: 11 | Loss: 14.0940\n",
            "Epoch 24 | Batch: 12 | Loss: 12.0559\n",
            "Epoch 24 | Batch: 13 | Loss: 17.8745\n",
            "Epoch 24 | Batch: 14 | Loss: 20.1142\n",
            "Epoch 24 | Batch: 15 | Loss: 13.4726\n",
            "Epoch 24 | Batch: 16 | Loss: 13.2553\n",
            "Epoch 24 | Batch: 17 | Loss: 13.0014\n",
            "Epoch 24 | Batch: 18 | Loss: 13.4963\n",
            "Epoch 24 | Batch: 19 | Loss: 13.3375\n",
            "Epoch 24 | Batch: 20 | Loss: 15.5254\n",
            "Epoch 24 | Batch: 21 | Loss: 13.5220\n",
            "Epoch 24 | Batch: 22 | Loss: 14.6246\n",
            "Epoch 24 | Batch: 23 | Loss: 17.2710\n",
            "Epoch 24 | Batch: 24 | Loss: 9.6276\n",
            "Epoch 25 | Batch: 1 | Loss: 13.0919\n",
            "Epoch 25 | Batch: 2 | Loss: 14.7573\n",
            "Epoch 25 | Batch: 3 | Loss: 8.8684\n",
            "Epoch 25 | Batch: 4 | Loss: 12.3392\n",
            "Epoch 25 | Batch: 5 | Loss: 12.4860\n",
            "Epoch 25 | Batch: 6 | Loss: 18.2418\n",
            "Epoch 25 | Batch: 7 | Loss: 14.2962\n",
            "Epoch 25 | Batch: 8 | Loss: 16.9737\n",
            "Epoch 25 | Batch: 9 | Loss: 14.5040\n",
            "Epoch 25 | Batch: 10 | Loss: 16.2200\n",
            "Epoch 25 | Batch: 11 | Loss: 15.4652\n",
            "Epoch 25 | Batch: 12 | Loss: 17.7563\n",
            "Epoch 25 | Batch: 13 | Loss: 19.9061\n",
            "Epoch 25 | Batch: 14 | Loss: 18.7947\n",
            "Epoch 25 | Batch: 15 | Loss: 14.7141\n",
            "Epoch 25 | Batch: 16 | Loss: 14.5768\n",
            "Epoch 25 | Batch: 17 | Loss: 15.3076\n",
            "Epoch 25 | Batch: 18 | Loss: 18.5922\n",
            "Epoch 25 | Batch: 19 | Loss: 13.8292\n",
            "Epoch 25 | Batch: 20 | Loss: 21.6024\n",
            "Epoch 25 | Batch: 21 | Loss: 14.2431\n",
            "Epoch 25 | Batch: 22 | Loss: 15.0357\n",
            "Epoch 25 | Batch: 23 | Loss: 15.6947\n",
            "Epoch 25 | Batch: 24 | Loss: 9.9185\n",
            "Epoch 26 | Batch: 1 | Loss: 14.0341\n",
            "Epoch 26 | Batch: 2 | Loss: 19.3762\n",
            "Epoch 26 | Batch: 3 | Loss: 11.8832\n",
            "Epoch 26 | Batch: 4 | Loss: 22.3244\n",
            "Epoch 26 | Batch: 5 | Loss: 20.4162\n",
            "Epoch 26 | Batch: 6 | Loss: 10.5856\n",
            "Epoch 26 | Batch: 7 | Loss: 13.1536\n",
            "Epoch 26 | Batch: 8 | Loss: 14.7335\n",
            "Epoch 26 | Batch: 9 | Loss: 15.3074\n",
            "Epoch 26 | Batch: 10 | Loss: 19.5856\n",
            "Epoch 26 | Batch: 11 | Loss: 17.6033\n",
            "Epoch 26 | Batch: 12 | Loss: 17.3136\n",
            "Epoch 26 | Batch: 13 | Loss: 15.1975\n",
            "Epoch 26 | Batch: 14 | Loss: 14.5290\n",
            "Epoch 26 | Batch: 15 | Loss: 12.7460\n",
            "Epoch 26 | Batch: 16 | Loss: 21.6167\n",
            "Epoch 26 | Batch: 17 | Loss: 21.3153\n",
            "Epoch 26 | Batch: 18 | Loss: 12.1897\n",
            "Epoch 26 | Batch: 19 | Loss: 16.3092\n",
            "Epoch 26 | Batch: 20 | Loss: 13.2849\n",
            "Epoch 26 | Batch: 21 | Loss: 10.7220\n",
            "Epoch 26 | Batch: 22 | Loss: 13.6160\n",
            "Epoch 26 | Batch: 23 | Loss: 15.1228\n",
            "Epoch 26 | Batch: 24 | Loss: 13.2977\n",
            "Epoch 27 | Batch: 1 | Loss: 14.8644\n",
            "Epoch 27 | Batch: 2 | Loss: 10.4597\n",
            "Epoch 27 | Batch: 3 | Loss: 13.3956\n",
            "Epoch 27 | Batch: 4 | Loss: 15.2034\n",
            "Epoch 27 | Batch: 5 | Loss: 15.0060\n",
            "Epoch 27 | Batch: 6 | Loss: 15.9962\n",
            "Epoch 27 | Batch: 7 | Loss: 10.7767\n",
            "Epoch 27 | Batch: 8 | Loss: 21.9333\n",
            "Epoch 27 | Batch: 9 | Loss: 11.9623\n",
            "Epoch 27 | Batch: 10 | Loss: 15.3279\n",
            "Epoch 27 | Batch: 11 | Loss: 13.4296\n",
            "Epoch 27 | Batch: 12 | Loss: 13.3811\n",
            "Epoch 27 | Batch: 13 | Loss: 14.0745\n",
            "Epoch 27 | Batch: 14 | Loss: 24.0659\n",
            "Epoch 27 | Batch: 15 | Loss: 15.6473\n",
            "Epoch 27 | Batch: 16 | Loss: 21.0006\n",
            "Epoch 27 | Batch: 17 | Loss: 14.6039\n",
            "Epoch 27 | Batch: 18 | Loss: 24.9509\n",
            "Epoch 27 | Batch: 19 | Loss: 17.9978\n",
            "Epoch 27 | Batch: 20 | Loss: 12.7519\n",
            "Epoch 27 | Batch: 21 | Loss: 16.4070\n",
            "Epoch 27 | Batch: 22 | Loss: 13.2216\n",
            "Epoch 27 | Batch: 23 | Loss: 14.6615\n",
            "Epoch 27 | Batch: 24 | Loss: 9.6110\n",
            "Epoch 28 | Batch: 1 | Loss: 18.9862\n",
            "Epoch 28 | Batch: 2 | Loss: 14.1483\n",
            "Epoch 28 | Batch: 3 | Loss: 15.9439\n",
            "Epoch 28 | Batch: 4 | Loss: 16.6669\n",
            "Epoch 28 | Batch: 5 | Loss: 17.4204\n",
            "Epoch 28 | Batch: 6 | Loss: 16.4103\n",
            "Epoch 28 | Batch: 7 | Loss: 15.3108\n",
            "Epoch 28 | Batch: 8 | Loss: 15.1161\n",
            "Epoch 28 | Batch: 9 | Loss: 16.4969\n",
            "Epoch 28 | Batch: 10 | Loss: 11.2050\n",
            "Epoch 28 | Batch: 11 | Loss: 19.2629\n",
            "Epoch 28 | Batch: 12 | Loss: 14.1514\n",
            "Epoch 28 | Batch: 13 | Loss: 15.5687\n",
            "Epoch 28 | Batch: 14 | Loss: 11.1550\n",
            "Epoch 28 | Batch: 15 | Loss: 15.9606\n",
            "Epoch 28 | Batch: 16 | Loss: 17.8675\n",
            "Epoch 28 | Batch: 17 | Loss: 13.2935\n",
            "Epoch 28 | Batch: 18 | Loss: 18.7910\n",
            "Epoch 28 | Batch: 19 | Loss: 16.0150\n",
            "Epoch 28 | Batch: 20 | Loss: 11.4872\n",
            "Epoch 28 | Batch: 21 | Loss: 12.5442\n",
            "Epoch 28 | Batch: 22 | Loss: 18.1587\n",
            "Epoch 28 | Batch: 23 | Loss: 17.8034\n",
            "Epoch 28 | Batch: 24 | Loss: 10.6643\n",
            "Epoch 29 | Batch: 1 | Loss: 20.7564\n",
            "Epoch 29 | Batch: 2 | Loss: 22.7465\n",
            "Epoch 29 | Batch: 3 | Loss: 18.6079\n",
            "Epoch 29 | Batch: 4 | Loss: 11.9684\n",
            "Epoch 29 | Batch: 5 | Loss: 15.9954\n",
            "Epoch 29 | Batch: 6 | Loss: 11.9649\n",
            "Epoch 29 | Batch: 7 | Loss: 13.1759\n",
            "Epoch 29 | Batch: 8 | Loss: 13.9317\n",
            "Epoch 29 | Batch: 9 | Loss: 14.6813\n",
            "Epoch 29 | Batch: 10 | Loss: 16.7818\n",
            "Epoch 29 | Batch: 11 | Loss: 16.4187\n",
            "Epoch 29 | Batch: 12 | Loss: 12.3262\n",
            "Epoch 29 | Batch: 13 | Loss: 18.9081\n",
            "Epoch 29 | Batch: 14 | Loss: 9.1248\n",
            "Epoch 29 | Batch: 15 | Loss: 20.7230\n",
            "Epoch 29 | Batch: 16 | Loss: 18.7038\n",
            "Epoch 29 | Batch: 17 | Loss: 18.4883\n",
            "Epoch 29 | Batch: 18 | Loss: 15.8010\n",
            "Epoch 29 | Batch: 19 | Loss: 11.1839\n",
            "Epoch 29 | Batch: 20 | Loss: 17.7835\n",
            "Epoch 29 | Batch: 21 | Loss: 12.4979\n",
            "Epoch 29 | Batch: 22 | Loss: 16.9311\n",
            "Epoch 29 | Batch: 23 | Loss: 18.5487\n",
            "Epoch 29 | Batch: 24 | Loss: 10.0153\n",
            "Epoch 30 | Batch: 1 | Loss: 16.2766\n",
            "Epoch 30 | Batch: 2 | Loss: 21.6426\n",
            "Epoch 30 | Batch: 3 | Loss: 16.7593\n",
            "Epoch 30 | Batch: 4 | Loss: 12.1634\n",
            "Epoch 30 | Batch: 5 | Loss: 10.6636\n",
            "Epoch 30 | Batch: 6 | Loss: 12.1067\n",
            "Epoch 30 | Batch: 7 | Loss: 12.2886\n",
            "Epoch 30 | Batch: 8 | Loss: 16.9632\n",
            "Epoch 30 | Batch: 9 | Loss: 22.4524\n",
            "Epoch 30 | Batch: 10 | Loss: 16.9184\n",
            "Epoch 30 | Batch: 11 | Loss: 11.3789\n",
            "Epoch 30 | Batch: 12 | Loss: 11.9800\n",
            "Epoch 30 | Batch: 13 | Loss: 15.7778\n",
            "Epoch 30 | Batch: 14 | Loss: 23.8233\n",
            "Epoch 30 | Batch: 15 | Loss: 17.0650\n",
            "Epoch 30 | Batch: 16 | Loss: 15.2130\n",
            "Epoch 30 | Batch: 17 | Loss: 13.3457\n",
            "Epoch 30 | Batch: 18 | Loss: 14.4591\n",
            "Epoch 30 | Batch: 19 | Loss: 15.2816\n",
            "Epoch 30 | Batch: 20 | Loss: 13.7603\n",
            "Epoch 30 | Batch: 21 | Loss: 14.1365\n",
            "Epoch 30 | Batch: 22 | Loss: 13.7498\n",
            "Epoch 30 | Batch: 23 | Loss: 16.3723\n",
            "Epoch 30 | Batch: 24 | Loss: 14.5110\n",
            "Epoch 31 | Batch: 1 | Loss: 14.1636\n",
            "Epoch 31 | Batch: 2 | Loss: 16.8595\n",
            "Epoch 31 | Batch: 3 | Loss: 11.3340\n",
            "Epoch 31 | Batch: 4 | Loss: 18.9711\n",
            "Epoch 31 | Batch: 5 | Loss: 12.6494\n",
            "Epoch 31 | Batch: 6 | Loss: 21.7876\n",
            "Epoch 31 | Batch: 7 | Loss: 15.1438\n",
            "Epoch 31 | Batch: 8 | Loss: 25.6523\n",
            "Epoch 31 | Batch: 9 | Loss: 19.5434\n",
            "Epoch 31 | Batch: 10 | Loss: 19.2511\n",
            "Epoch 31 | Batch: 11 | Loss: 12.6049\n",
            "Epoch 31 | Batch: 12 | Loss: 17.1727\n",
            "Epoch 31 | Batch: 13 | Loss: 13.1719\n",
            "Epoch 31 | Batch: 14 | Loss: 12.0158\n",
            "Epoch 31 | Batch: 15 | Loss: 15.3082\n",
            "Epoch 31 | Batch: 16 | Loss: 12.0647\n",
            "Epoch 31 | Batch: 17 | Loss: 12.8439\n",
            "Epoch 31 | Batch: 18 | Loss: 10.2974\n",
            "Epoch 31 | Batch: 19 | Loss: 18.2115\n",
            "Epoch 31 | Batch: 20 | Loss: 17.9704\n",
            "Epoch 31 | Batch: 21 | Loss: 15.1322\n",
            "Epoch 31 | Batch: 22 | Loss: 20.4515\n",
            "Epoch 31 | Batch: 23 | Loss: 19.3912\n",
            "Epoch 31 | Batch: 24 | Loss: 9.1811\n",
            "Epoch 32 | Batch: 1 | Loss: 15.4083\n",
            "Epoch 32 | Batch: 2 | Loss: 14.1417\n",
            "Epoch 32 | Batch: 3 | Loss: 13.7575\n",
            "Epoch 32 | Batch: 4 | Loss: 13.1572\n",
            "Epoch 32 | Batch: 5 | Loss: 15.5572\n",
            "Epoch 32 | Batch: 6 | Loss: 20.9635\n",
            "Epoch 32 | Batch: 7 | Loss: 19.8595\n",
            "Epoch 32 | Batch: 8 | Loss: 13.3679\n",
            "Epoch 32 | Batch: 9 | Loss: 13.9235\n",
            "Epoch 32 | Batch: 10 | Loss: 15.2428\n",
            "Epoch 32 | Batch: 11 | Loss: 16.4513\n",
            "Epoch 32 | Batch: 12 | Loss: 12.9803\n",
            "Epoch 32 | Batch: 13 | Loss: 13.9795\n",
            "Epoch 32 | Batch: 14 | Loss: 15.3090\n",
            "Epoch 32 | Batch: 15 | Loss: 13.3856\n",
            "Epoch 32 | Batch: 16 | Loss: 10.6726\n",
            "Epoch 32 | Batch: 17 | Loss: 21.5593\n",
            "Epoch 32 | Batch: 18 | Loss: 17.0730\n",
            "Epoch 32 | Batch: 19 | Loss: 16.3663\n",
            "Epoch 32 | Batch: 20 | Loss: 16.2023\n",
            "Epoch 32 | Batch: 21 | Loss: 17.5022\n",
            "Epoch 32 | Batch: 22 | Loss: 14.1816\n",
            "Epoch 32 | Batch: 23 | Loss: 14.5973\n",
            "Epoch 32 | Batch: 24 | Loss: 11.0960\n",
            "Epoch 33 | Batch: 1 | Loss: 14.6376\n",
            "Epoch 33 | Batch: 2 | Loss: 12.2010\n",
            "Epoch 33 | Batch: 3 | Loss: 16.4269\n",
            "Epoch 33 | Batch: 4 | Loss: 18.0841\n",
            "Epoch 33 | Batch: 5 | Loss: 12.0913\n",
            "Epoch 33 | Batch: 6 | Loss: 15.3129\n",
            "Epoch 33 | Batch: 7 | Loss: 10.6623\n",
            "Epoch 33 | Batch: 8 | Loss: 13.9377\n",
            "Epoch 33 | Batch: 9 | Loss: 14.2645\n",
            "Epoch 33 | Batch: 10 | Loss: 19.2141\n",
            "Epoch 33 | Batch: 11 | Loss: 18.6055\n",
            "Epoch 33 | Batch: 12 | Loss: 13.4564\n",
            "Epoch 33 | Batch: 13 | Loss: 18.7901\n",
            "Epoch 33 | Batch: 14 | Loss: 13.0179\n",
            "Epoch 33 | Batch: 15 | Loss: 18.6447\n",
            "Epoch 33 | Batch: 16 | Loss: 18.6853\n",
            "Epoch 33 | Batch: 17 | Loss: 17.3981\n",
            "Epoch 33 | Batch: 18 | Loss: 19.3306\n",
            "Epoch 33 | Batch: 19 | Loss: 15.1802\n",
            "Epoch 33 | Batch: 20 | Loss: 13.5984\n",
            "Epoch 33 | Batch: 21 | Loss: 17.8743\n",
            "Epoch 33 | Batch: 22 | Loss: 14.5595\n",
            "Epoch 33 | Batch: 23 | Loss: 14.4836\n",
            "Epoch 33 | Batch: 24 | Loss: 6.4428\n",
            "Epoch 34 | Batch: 1 | Loss: 13.8998\n",
            "Epoch 34 | Batch: 2 | Loss: 19.6732\n",
            "Epoch 34 | Batch: 3 | Loss: 12.5724\n",
            "Epoch 34 | Batch: 4 | Loss: 18.7650\n",
            "Epoch 34 | Batch: 5 | Loss: 20.1199\n",
            "Epoch 34 | Batch: 6 | Loss: 18.9757\n",
            "Epoch 34 | Batch: 7 | Loss: 15.1751\n",
            "Epoch 34 | Batch: 8 | Loss: 14.9316\n",
            "Epoch 34 | Batch: 9 | Loss: 18.1034\n",
            "Epoch 34 | Batch: 10 | Loss: 11.9932\n",
            "Epoch 34 | Batch: 11 | Loss: 14.2966\n",
            "Epoch 34 | Batch: 12 | Loss: 12.9721\n",
            "Epoch 34 | Batch: 13 | Loss: 11.0694\n",
            "Epoch 34 | Batch: 14 | Loss: 14.2935\n",
            "Epoch 34 | Batch: 15 | Loss: 11.1492\n",
            "Epoch 34 | Batch: 16 | Loss: 13.0806\n",
            "Epoch 34 | Batch: 17 | Loss: 11.2869\n",
            "Epoch 34 | Batch: 18 | Loss: 22.0348\n",
            "Epoch 34 | Batch: 19 | Loss: 16.5245\n",
            "Epoch 34 | Batch: 20 | Loss: 20.7256\n",
            "Epoch 34 | Batch: 21 | Loss: 16.1766\n",
            "Epoch 34 | Batch: 22 | Loss: 13.7172\n",
            "Epoch 34 | Batch: 23 | Loss: 17.1404\n",
            "Epoch 34 | Batch: 24 | Loss: 9.0541\n",
            "Epoch 35 | Batch: 1 | Loss: 16.3393\n",
            "Epoch 35 | Batch: 2 | Loss: 15.3418\n",
            "Epoch 35 | Batch: 3 | Loss: 11.3740\n",
            "Epoch 35 | Batch: 4 | Loss: 16.5065\n",
            "Epoch 35 | Batch: 5 | Loss: 17.3615\n",
            "Epoch 35 | Batch: 6 | Loss: 12.1192\n",
            "Epoch 35 | Batch: 7 | Loss: 15.4212\n",
            "Epoch 35 | Batch: 8 | Loss: 15.9460\n",
            "Epoch 35 | Batch: 9 | Loss: 11.4857\n",
            "Epoch 35 | Batch: 10 | Loss: 10.1357\n",
            "Epoch 35 | Batch: 11 | Loss: 22.7311\n",
            "Epoch 35 | Batch: 12 | Loss: 13.7289\n",
            "Epoch 35 | Batch: 13 | Loss: 12.9121\n",
            "Epoch 35 | Batch: 14 | Loss: 22.8403\n",
            "Epoch 35 | Batch: 15 | Loss: 12.0221\n",
            "Epoch 35 | Batch: 16 | Loss: 9.7362\n",
            "Epoch 35 | Batch: 17 | Loss: 17.0885\n",
            "Epoch 35 | Batch: 18 | Loss: 15.5467\n",
            "Epoch 35 | Batch: 19 | Loss: 15.4831\n",
            "Epoch 35 | Batch: 20 | Loss: 10.9539\n",
            "Epoch 35 | Batch: 21 | Loss: 17.9945\n",
            "Epoch 35 | Batch: 22 | Loss: 23.7758\n",
            "Epoch 35 | Batch: 23 | Loss: 15.0710\n",
            "Epoch 35 | Batch: 24 | Loss: 12.7065\n",
            "Epoch 36 | Batch: 1 | Loss: 17.2653\n",
            "Epoch 36 | Batch: 2 | Loss: 14.2877\n",
            "Epoch 36 | Batch: 3 | Loss: 11.4109\n",
            "Epoch 36 | Batch: 4 | Loss: 16.1898\n",
            "Epoch 36 | Batch: 5 | Loss: 12.4309\n",
            "Epoch 36 | Batch: 6 | Loss: 10.7504\n",
            "Epoch 36 | Batch: 7 | Loss: 25.2907\n",
            "Epoch 36 | Batch: 8 | Loss: 17.7922\n",
            "Epoch 36 | Batch: 9 | Loss: 12.3356\n",
            "Epoch 36 | Batch: 10 | Loss: 16.9335\n",
            "Epoch 36 | Batch: 11 | Loss: 17.3785\n",
            "Epoch 36 | Batch: 12 | Loss: 17.6794\n",
            "Epoch 36 | Batch: 13 | Loss: 14.9944\n",
            "Epoch 36 | Batch: 14 | Loss: 14.6774\n",
            "Epoch 36 | Batch: 15 | Loss: 16.8005\n",
            "Epoch 36 | Batch: 16 | Loss: 16.6208\n",
            "Epoch 36 | Batch: 17 | Loss: 16.2172\n",
            "Epoch 36 | Batch: 18 | Loss: 17.2270\n",
            "Epoch 36 | Batch: 19 | Loss: 14.7254\n",
            "Epoch 36 | Batch: 20 | Loss: 16.6233\n",
            "Epoch 36 | Batch: 21 | Loss: 15.9355\n",
            "Epoch 36 | Batch: 22 | Loss: 19.4875\n",
            "Epoch 36 | Batch: 23 | Loss: 14.1516\n",
            "Epoch 36 | Batch: 24 | Loss: 6.1751\n",
            "Epoch 37 | Batch: 1 | Loss: 12.7431\n",
            "Epoch 37 | Batch: 2 | Loss: 15.1814\n",
            "Epoch 37 | Batch: 3 | Loss: 10.4697\n",
            "Epoch 37 | Batch: 4 | Loss: 14.7385\n",
            "Epoch 37 | Batch: 5 | Loss: 18.3181\n",
            "Epoch 37 | Batch: 6 | Loss: 16.2788\n",
            "Epoch 37 | Batch: 7 | Loss: 25.2748\n",
            "Epoch 37 | Batch: 8 | Loss: 16.6080\n",
            "Epoch 37 | Batch: 9 | Loss: 15.7695\n",
            "Epoch 37 | Batch: 10 | Loss: 11.9219\n",
            "Epoch 37 | Batch: 11 | Loss: 17.4868\n",
            "Epoch 37 | Batch: 12 | Loss: 14.2539\n",
            "Epoch 37 | Batch: 13 | Loss: 20.0949\n",
            "Epoch 37 | Batch: 14 | Loss: 11.2425\n",
            "Epoch 37 | Batch: 15 | Loss: 17.0004\n",
            "Epoch 37 | Batch: 16 | Loss: 20.4712\n",
            "Epoch 37 | Batch: 17 | Loss: 21.4324\n",
            "Epoch 37 | Batch: 18 | Loss: 13.0039\n",
            "Epoch 37 | Batch: 19 | Loss: 17.8322\n",
            "Epoch 37 | Batch: 20 | Loss: 12.3953\n",
            "Epoch 37 | Batch: 21 | Loss: 8.1405\n",
            "Epoch 37 | Batch: 22 | Loss: 19.1375\n",
            "Epoch 37 | Batch: 23 | Loss: 15.9821\n",
            "Epoch 37 | Batch: 24 | Loss: 11.9758\n",
            "Epoch 38 | Batch: 1 | Loss: 15.0079\n",
            "Epoch 38 | Batch: 2 | Loss: 16.2811\n",
            "Epoch 38 | Batch: 3 | Loss: 16.6072\n",
            "Epoch 38 | Batch: 4 | Loss: 11.3840\n",
            "Epoch 38 | Batch: 5 | Loss: 22.1264\n",
            "Epoch 38 | Batch: 6 | Loss: 21.9946\n",
            "Epoch 38 | Batch: 7 | Loss: 14.6443\n",
            "Epoch 38 | Batch: 8 | Loss: 15.5136\n",
            "Epoch 38 | Batch: 9 | Loss: 15.8052\n",
            "Epoch 38 | Batch: 10 | Loss: 14.5963\n",
            "Epoch 38 | Batch: 11 | Loss: 11.2581\n",
            "Epoch 38 | Batch: 12 | Loss: 18.7460\n",
            "Epoch 38 | Batch: 13 | Loss: 14.6177\n",
            "Epoch 38 | Batch: 14 | Loss: 13.6507\n",
            "Epoch 38 | Batch: 15 | Loss: 11.7282\n",
            "Epoch 38 | Batch: 16 | Loss: 14.3267\n",
            "Epoch 38 | Batch: 17 | Loss: 15.7853\n",
            "Epoch 38 | Batch: 18 | Loss: 10.6359\n",
            "Epoch 38 | Batch: 19 | Loss: 18.8717\n",
            "Epoch 38 | Batch: 20 | Loss: 14.4477\n",
            "Epoch 38 | Batch: 21 | Loss: 13.7465\n",
            "Epoch 38 | Batch: 22 | Loss: 19.6997\n",
            "Epoch 38 | Batch: 23 | Loss: 16.5287\n",
            "Epoch 38 | Batch: 24 | Loss: 11.7154\n",
            "Epoch 39 | Batch: 1 | Loss: 14.0149\n",
            "Epoch 39 | Batch: 2 | Loss: 16.5162\n",
            "Epoch 39 | Batch: 3 | Loss: 18.1986\n",
            "Epoch 39 | Batch: 4 | Loss: 16.3483\n",
            "Epoch 39 | Batch: 5 | Loss: 16.7014\n",
            "Epoch 39 | Batch: 6 | Loss: 19.8237\n",
            "Epoch 39 | Batch: 7 | Loss: 14.8564\n",
            "Epoch 39 | Batch: 8 | Loss: 12.0507\n",
            "Epoch 39 | Batch: 9 | Loss: 11.6819\n",
            "Epoch 39 | Batch: 10 | Loss: 17.1617\n",
            "Epoch 39 | Batch: 11 | Loss: 21.3652\n",
            "Epoch 39 | Batch: 12 | Loss: 21.5075\n",
            "Epoch 39 | Batch: 13 | Loss: 22.2557\n",
            "Epoch 39 | Batch: 14 | Loss: 17.3403\n",
            "Epoch 39 | Batch: 15 | Loss: 14.5035\n",
            "Epoch 39 | Batch: 16 | Loss: 15.0688\n",
            "Epoch 39 | Batch: 17 | Loss: 26.9292\n",
            "Epoch 39 | Batch: 18 | Loss: 19.3839\n",
            "Epoch 39 | Batch: 19 | Loss: 11.8531\n",
            "Epoch 39 | Batch: 20 | Loss: 13.8971\n",
            "Epoch 39 | Batch: 21 | Loss: 12.0414\n",
            "Epoch 39 | Batch: 22 | Loss: 14.8423\n",
            "Epoch 39 | Batch: 23 | Loss: 13.9971\n",
            "Epoch 39 | Batch: 24 | Loss: 11.1687\n",
            "Epoch 40 | Batch: 1 | Loss: 18.4854\n",
            "Epoch 40 | Batch: 2 | Loss: 20.5316\n",
            "Epoch 40 | Batch: 3 | Loss: 14.0881\n",
            "Epoch 40 | Batch: 4 | Loss: 12.8610\n",
            "Epoch 40 | Batch: 5 | Loss: 18.5989\n",
            "Epoch 40 | Batch: 6 | Loss: 13.3371\n",
            "Epoch 40 | Batch: 7 | Loss: 15.7792\n",
            "Epoch 40 | Batch: 8 | Loss: 10.3648\n",
            "Epoch 40 | Batch: 9 | Loss: 15.6402\n",
            "Epoch 40 | Batch: 10 | Loss: 15.0627\n",
            "Epoch 40 | Batch: 11 | Loss: 13.4770\n",
            "Epoch 40 | Batch: 12 | Loss: 14.0167\n",
            "Epoch 40 | Batch: 13 | Loss: 15.1758\n",
            "Epoch 40 | Batch: 14 | Loss: 16.5553\n",
            "Epoch 40 | Batch: 15 | Loss: 16.2943\n",
            "Epoch 40 | Batch: 16 | Loss: 12.3943\n",
            "Epoch 40 | Batch: 17 | Loss: 11.8636\n",
            "Epoch 40 | Batch: 18 | Loss: 21.9040\n",
            "Epoch 40 | Batch: 19 | Loss: 14.1063\n",
            "Epoch 40 | Batch: 20 | Loss: 14.5739\n",
            "Epoch 40 | Batch: 21 | Loss: 18.6878\n",
            "Epoch 40 | Batch: 22 | Loss: 13.7593\n",
            "Epoch 40 | Batch: 23 | Loss: 9.4517\n",
            "Epoch 40 | Batch: 24 | Loss: 17.0932\n",
            "Epoch 41 | Batch: 1 | Loss: 12.8527\n",
            "Epoch 41 | Batch: 2 | Loss: 15.4755\n",
            "Epoch 41 | Batch: 3 | Loss: 18.8894\n",
            "Epoch 41 | Batch: 4 | Loss: 15.4833\n",
            "Epoch 41 | Batch: 5 | Loss: 21.2709\n",
            "Epoch 41 | Batch: 6 | Loss: 14.1417\n",
            "Epoch 41 | Batch: 7 | Loss: 15.6047\n",
            "Epoch 41 | Batch: 8 | Loss: 20.0446\n",
            "Epoch 41 | Batch: 9 | Loss: 18.0972\n",
            "Epoch 41 | Batch: 10 | Loss: 13.9925\n",
            "Epoch 41 | Batch: 11 | Loss: 15.9483\n",
            "Epoch 41 | Batch: 12 | Loss: 15.5348\n",
            "Epoch 41 | Batch: 13 | Loss: 16.9605\n",
            "Epoch 41 | Batch: 14 | Loss: 11.2625\n",
            "Epoch 41 | Batch: 15 | Loss: 17.3316\n",
            "Epoch 41 | Batch: 16 | Loss: 16.0132\n",
            "Epoch 41 | Batch: 17 | Loss: 11.4001\n",
            "Epoch 41 | Batch: 18 | Loss: 15.4719\n",
            "Epoch 41 | Batch: 19 | Loss: 16.5483\n",
            "Epoch 41 | Batch: 20 | Loss: 15.9905\n",
            "Epoch 41 | Batch: 21 | Loss: 12.6260\n",
            "Epoch 41 | Batch: 22 | Loss: 12.5239\n",
            "Epoch 41 | Batch: 23 | Loss: 17.2885\n",
            "Epoch 41 | Batch: 24 | Loss: 15.2949\n",
            "Epoch 42 | Batch: 1 | Loss: 14.1092\n",
            "Epoch 42 | Batch: 2 | Loss: 12.7283\n",
            "Epoch 42 | Batch: 3 | Loss: 11.5097\n",
            "Epoch 42 | Batch: 4 | Loss: 12.4655\n",
            "Epoch 42 | Batch: 5 | Loss: 12.9071\n",
            "Epoch 42 | Batch: 6 | Loss: 19.1100\n",
            "Epoch 42 | Batch: 7 | Loss: 17.2344\n",
            "Epoch 42 | Batch: 8 | Loss: 13.7007\n",
            "Epoch 42 | Batch: 9 | Loss: 14.8008\n",
            "Epoch 42 | Batch: 10 | Loss: 13.3961\n",
            "Epoch 42 | Batch: 11 | Loss: 17.5717\n",
            "Epoch 42 | Batch: 12 | Loss: 13.5786\n",
            "Epoch 42 | Batch: 13 | Loss: 14.9834\n",
            "Epoch 42 | Batch: 14 | Loss: 17.5828\n",
            "Epoch 42 | Batch: 15 | Loss: 11.8771\n",
            "Epoch 42 | Batch: 16 | Loss: 18.0340\n",
            "Epoch 42 | Batch: 17 | Loss: 16.4086\n",
            "Epoch 42 | Batch: 18 | Loss: 12.6894\n",
            "Epoch 42 | Batch: 19 | Loss: 15.4805\n",
            "Epoch 42 | Batch: 20 | Loss: 16.0842\n",
            "Epoch 42 | Batch: 21 | Loss: 16.9978\n",
            "Epoch 42 | Batch: 22 | Loss: 19.9640\n",
            "Epoch 42 | Batch: 23 | Loss: 16.9357\n",
            "Epoch 42 | Batch: 24 | Loss: 14.3629\n",
            "Epoch 43 | Batch: 1 | Loss: 11.5293\n",
            "Epoch 43 | Batch: 2 | Loss: 21.7208\n",
            "Epoch 43 | Batch: 3 | Loss: 14.6562\n",
            "Epoch 43 | Batch: 4 | Loss: 13.8279\n",
            "Epoch 43 | Batch: 5 | Loss: 12.1851\n",
            "Epoch 43 | Batch: 6 | Loss: 10.5146\n",
            "Epoch 43 | Batch: 7 | Loss: 12.5936\n",
            "Epoch 43 | Batch: 8 | Loss: 19.6415\n",
            "Epoch 43 | Batch: 9 | Loss: 16.5659\n",
            "Epoch 43 | Batch: 10 | Loss: 20.6542\n",
            "Epoch 43 | Batch: 11 | Loss: 14.9421\n",
            "Epoch 43 | Batch: 12 | Loss: 15.8551\n",
            "Epoch 43 | Batch: 13 | Loss: 25.5007\n",
            "Epoch 43 | Batch: 14 | Loss: 24.2561\n",
            "Epoch 43 | Batch: 15 | Loss: 12.3852\n",
            "Epoch 43 | Batch: 16 | Loss: 15.1435\n",
            "Epoch 43 | Batch: 17 | Loss: 17.0596\n",
            "Epoch 43 | Batch: 18 | Loss: 15.2291\n",
            "Epoch 43 | Batch: 19 | Loss: 14.0851\n",
            "Epoch 43 | Batch: 20 | Loss: 12.3112\n",
            "Epoch 43 | Batch: 21 | Loss: 20.2433\n",
            "Epoch 43 | Batch: 22 | Loss: 14.7080\n",
            "Epoch 43 | Batch: 23 | Loss: 15.9239\n",
            "Epoch 43 | Batch: 24 | Loss: 7.4094\n",
            "Epoch 44 | Batch: 1 | Loss: 17.0045\n",
            "Epoch 44 | Batch: 2 | Loss: 12.1707\n",
            "Epoch 44 | Batch: 3 | Loss: 14.5179\n",
            "Epoch 44 | Batch: 4 | Loss: 16.8686\n",
            "Epoch 44 | Batch: 5 | Loss: 13.0890\n",
            "Epoch 44 | Batch: 6 | Loss: 13.8277\n",
            "Epoch 44 | Batch: 7 | Loss: 24.8182\n",
            "Epoch 44 | Batch: 8 | Loss: 16.9665\n",
            "Epoch 44 | Batch: 9 | Loss: 13.8326\n",
            "Epoch 44 | Batch: 10 | Loss: 15.1039\n",
            "Epoch 44 | Batch: 11 | Loss: 20.3531\n",
            "Epoch 44 | Batch: 12 | Loss: 19.3255\n",
            "Epoch 44 | Batch: 13 | Loss: 15.9364\n",
            "Epoch 44 | Batch: 14 | Loss: 17.2727\n",
            "Epoch 44 | Batch: 15 | Loss: 15.0878\n",
            "Epoch 44 | Batch: 16 | Loss: 14.8848\n",
            "Epoch 44 | Batch: 17 | Loss: 12.7867\n",
            "Epoch 44 | Batch: 18 | Loss: 11.5827\n",
            "Epoch 44 | Batch: 19 | Loss: 19.0630\n",
            "Epoch 44 | Batch: 20 | Loss: 15.5899\n",
            "Epoch 44 | Batch: 21 | Loss: 14.5972\n",
            "Epoch 44 | Batch: 22 | Loss: 12.7604\n",
            "Epoch 44 | Batch: 23 | Loss: 15.5169\n",
            "Epoch 44 | Batch: 24 | Loss: 7.2374\n",
            "Epoch 45 | Batch: 1 | Loss: 13.3641\n",
            "Epoch 45 | Batch: 2 | Loss: 15.2672\n",
            "Epoch 45 | Batch: 3 | Loss: 16.4177\n",
            "Epoch 45 | Batch: 4 | Loss: 15.9507\n",
            "Epoch 45 | Batch: 5 | Loss: 9.7741\n",
            "Epoch 45 | Batch: 6 | Loss: 19.2491\n",
            "Epoch 45 | Batch: 7 | Loss: 19.6111\n",
            "Epoch 45 | Batch: 8 | Loss: 11.7297\n",
            "Epoch 45 | Batch: 9 | Loss: 19.9114\n",
            "Epoch 45 | Batch: 10 | Loss: 13.9244\n",
            "Epoch 45 | Batch: 11 | Loss: 14.9119\n",
            "Epoch 45 | Batch: 12 | Loss: 10.0097\n",
            "Epoch 45 | Batch: 13 | Loss: 15.0616\n",
            "Epoch 45 | Batch: 14 | Loss: 11.8641\n",
            "Epoch 45 | Batch: 15 | Loss: 22.9633\n",
            "Epoch 45 | Batch: 16 | Loss: 15.6627\n",
            "Epoch 45 | Batch: 17 | Loss: 20.4822\n",
            "Epoch 45 | Batch: 18 | Loss: 12.5351\n",
            "Epoch 45 | Batch: 19 | Loss: 16.5248\n",
            "Epoch 45 | Batch: 20 | Loss: 17.7707\n",
            "Epoch 45 | Batch: 21 | Loss: 23.6150\n",
            "Epoch 45 | Batch: 22 | Loss: 12.4996\n",
            "Epoch 45 | Batch: 23 | Loss: 12.0781\n",
            "Epoch 45 | Batch: 24 | Loss: 7.8541\n",
            "Epoch 46 | Batch: 1 | Loss: 15.4985\n",
            "Epoch 46 | Batch: 2 | Loss: 19.6651\n",
            "Epoch 46 | Batch: 3 | Loss: 9.2992\n",
            "Epoch 46 | Batch: 4 | Loss: 19.4213\n",
            "Epoch 46 | Batch: 5 | Loss: 15.7195\n",
            "Epoch 46 | Batch: 6 | Loss: 14.2669\n",
            "Epoch 46 | Batch: 7 | Loss: 9.7983\n",
            "Epoch 46 | Batch: 8 | Loss: 17.3383\n",
            "Epoch 46 | Batch: 9 | Loss: 19.6571\n",
            "Epoch 46 | Batch: 10 | Loss: 10.6775\n",
            "Epoch 46 | Batch: 11 | Loss: 15.7868\n",
            "Epoch 46 | Batch: 12 | Loss: 17.3579\n",
            "Epoch 46 | Batch: 13 | Loss: 16.4002\n",
            "Epoch 46 | Batch: 14 | Loss: 15.5373\n",
            "Epoch 46 | Batch: 15 | Loss: 16.2240\n",
            "Epoch 46 | Batch: 16 | Loss: 16.8874\n",
            "Epoch 46 | Batch: 17 | Loss: 13.6635\n",
            "Epoch 46 | Batch: 18 | Loss: 17.4753\n",
            "Epoch 46 | Batch: 19 | Loss: 13.4832\n",
            "Epoch 46 | Batch: 20 | Loss: 15.0178\n",
            "Epoch 46 | Batch: 21 | Loss: 18.0496\n",
            "Epoch 46 | Batch: 22 | Loss: 12.3496\n",
            "Epoch 46 | Batch: 23 | Loss: 15.0422\n",
            "Epoch 46 | Batch: 24 | Loss: 7.7312\n",
            "Epoch 47 | Batch: 1 | Loss: 21.5393\n",
            "Epoch 47 | Batch: 2 | Loss: 14.7984\n",
            "Epoch 47 | Batch: 3 | Loss: 16.6481\n",
            "Epoch 47 | Batch: 4 | Loss: 15.9972\n",
            "Epoch 47 | Batch: 5 | Loss: 16.4650\n",
            "Epoch 47 | Batch: 6 | Loss: 17.2071\n",
            "Epoch 47 | Batch: 7 | Loss: 15.3132\n",
            "Epoch 47 | Batch: 8 | Loss: 13.4475\n",
            "Epoch 47 | Batch: 9 | Loss: 16.1377\n",
            "Epoch 47 | Batch: 10 | Loss: 14.1590\n",
            "Epoch 47 | Batch: 11 | Loss: 10.2737\n",
            "Epoch 47 | Batch: 12 | Loss: 14.8165\n",
            "Epoch 47 | Batch: 13 | Loss: 13.5820\n",
            "Epoch 47 | Batch: 14 | Loss: 13.9678\n",
            "Epoch 47 | Batch: 15 | Loss: 7.7218\n",
            "Epoch 47 | Batch: 16 | Loss: 17.2393\n",
            "Epoch 47 | Batch: 17 | Loss: 14.6429\n",
            "Epoch 47 | Batch: 18 | Loss: 16.9381\n",
            "Epoch 47 | Batch: 19 | Loss: 14.3139\n",
            "Epoch 47 | Batch: 20 | Loss: 21.2788\n",
            "Epoch 47 | Batch: 21 | Loss: 18.5880\n",
            "Epoch 47 | Batch: 22 | Loss: 17.9510\n",
            "Epoch 47 | Batch: 23 | Loss: 14.7592\n",
            "Epoch 47 | Batch: 24 | Loss: 10.4278\n",
            "Epoch 48 | Batch: 1 | Loss: 16.6427\n",
            "Epoch 48 | Batch: 2 | Loss: 17.6641\n",
            "Epoch 48 | Batch: 3 | Loss: 22.4826\n",
            "Epoch 48 | Batch: 4 | Loss: 17.0366\n",
            "Epoch 48 | Batch: 5 | Loss: 13.1303\n",
            "Epoch 48 | Batch: 6 | Loss: 13.8006\n",
            "Epoch 48 | Batch: 7 | Loss: 18.2710\n",
            "Epoch 48 | Batch: 8 | Loss: 13.5566\n",
            "Epoch 48 | Batch: 9 | Loss: 16.6769\n",
            "Epoch 48 | Batch: 10 | Loss: 13.6275\n",
            "Epoch 48 | Batch: 11 | Loss: 15.8400\n",
            "Epoch 48 | Batch: 12 | Loss: 15.8545\n",
            "Epoch 48 | Batch: 13 | Loss: 13.6061\n",
            "Epoch 48 | Batch: 14 | Loss: 13.9349\n",
            "Epoch 48 | Batch: 15 | Loss: 17.0885\n",
            "Epoch 48 | Batch: 16 | Loss: 11.6668\n",
            "Epoch 48 | Batch: 17 | Loss: 15.3828\n",
            "Epoch 48 | Batch: 18 | Loss: 10.8034\n",
            "Epoch 48 | Batch: 19 | Loss: 16.2366\n",
            "Epoch 48 | Batch: 20 | Loss: 12.0454\n",
            "Epoch 48 | Batch: 21 | Loss: 18.8555\n",
            "Epoch 48 | Batch: 22 | Loss: 18.6103\n",
            "Epoch 48 | Batch: 23 | Loss: 16.2846\n",
            "Epoch 48 | Batch: 24 | Loss: 14.1015\n",
            "Epoch 49 | Batch: 1 | Loss: 15.1460\n",
            "Epoch 49 | Batch: 2 | Loss: 13.1564\n",
            "Epoch 49 | Batch: 3 | Loss: 18.7203\n",
            "Epoch 49 | Batch: 4 | Loss: 20.7945\n",
            "Epoch 49 | Batch: 5 | Loss: 17.2122\n",
            "Epoch 49 | Batch: 6 | Loss: 11.3796\n",
            "Epoch 49 | Batch: 7 | Loss: 16.1740\n",
            "Epoch 49 | Batch: 8 | Loss: 16.0624\n",
            "Epoch 49 | Batch: 9 | Loss: 15.9608\n",
            "Epoch 49 | Batch: 10 | Loss: 15.1235\n",
            "Epoch 49 | Batch: 11 | Loss: 13.1765\n",
            "Epoch 49 | Batch: 12 | Loss: 13.3712\n",
            "Epoch 49 | Batch: 13 | Loss: 17.0407\n",
            "Epoch 49 | Batch: 14 | Loss: 15.2964\n",
            "Epoch 49 | Batch: 15 | Loss: 14.8019\n",
            "Epoch 49 | Batch: 16 | Loss: 9.3562\n",
            "Epoch 49 | Batch: 17 | Loss: 16.0364\n",
            "Epoch 49 | Batch: 18 | Loss: 15.5651\n",
            "Epoch 49 | Batch: 19 | Loss: 18.8789\n",
            "Epoch 49 | Batch: 20 | Loss: 17.7569\n",
            "Epoch 49 | Batch: 21 | Loss: 15.7343\n",
            "Epoch 49 | Batch: 22 | Loss: 12.5010\n",
            "Epoch 49 | Batch: 23 | Loss: 15.8513\n",
            "Epoch 49 | Batch: 24 | Loss: 10.7204\n",
            "Epoch 50 | Batch: 1 | Loss: 19.2719\n",
            "Epoch 50 | Batch: 2 | Loss: 13.2632\n",
            "Epoch 50 | Batch: 3 | Loss: 15.1437\n",
            "Epoch 50 | Batch: 4 | Loss: 16.6657\n",
            "Epoch 50 | Batch: 5 | Loss: 17.3954\n",
            "Epoch 50 | Batch: 6 | Loss: 17.2261\n",
            "Epoch 50 | Batch: 7 | Loss: 12.0851\n",
            "Epoch 50 | Batch: 8 | Loss: 14.9735\n",
            "Epoch 50 | Batch: 9 | Loss: 20.3428\n",
            "Epoch 50 | Batch: 10 | Loss: 23.4811\n",
            "Epoch 50 | Batch: 11 | Loss: 18.5755\n",
            "Epoch 50 | Batch: 12 | Loss: 16.1531\n",
            "Epoch 50 | Batch: 13 | Loss: 16.7930\n",
            "Epoch 50 | Batch: 14 | Loss: 13.4125\n",
            "Epoch 50 | Batch: 15 | Loss: 17.4495\n",
            "Epoch 50 | Batch: 16 | Loss: 8.3450\n",
            "Epoch 50 | Batch: 17 | Loss: 12.0612\n",
            "Epoch 50 | Batch: 18 | Loss: 16.3124\n",
            "Epoch 50 | Batch: 19 | Loss: 9.0115\n",
            "Epoch 50 | Batch: 20 | Loss: 16.3802\n",
            "Epoch 50 | Batch: 21 | Loss: 17.8246\n",
            "Epoch 50 | Batch: 22 | Loss: 15.8948\n",
            "Epoch 50 | Batch: 23 | Loss: 13.2825\n",
            "Epoch 50 | Batch: 24 | Loss: 10.0937\n",
            "Epoch 51 | Batch: 1 | Loss: 12.6246\n",
            "Epoch 51 | Batch: 2 | Loss: 12.8291\n",
            "Epoch 51 | Batch: 3 | Loss: 13.4834\n",
            "Epoch 51 | Batch: 4 | Loss: 16.9963\n",
            "Epoch 51 | Batch: 5 | Loss: 9.2972\n",
            "Epoch 51 | Batch: 6 | Loss: 9.9642\n",
            "Epoch 51 | Batch: 7 | Loss: 18.6635\n",
            "Epoch 51 | Batch: 8 | Loss: 20.7516\n",
            "Epoch 51 | Batch: 9 | Loss: 13.3690\n",
            "Epoch 51 | Batch: 10 | Loss: 15.5493\n",
            "Epoch 51 | Batch: 11 | Loss: 14.8665\n",
            "Epoch 51 | Batch: 12 | Loss: 18.1149\n",
            "Epoch 51 | Batch: 13 | Loss: 19.3280\n",
            "Epoch 51 | Batch: 14 | Loss: 9.9876\n",
            "Epoch 51 | Batch: 15 | Loss: 12.4595\n",
            "Epoch 51 | Batch: 16 | Loss: 18.2719\n",
            "Epoch 51 | Batch: 17 | Loss: 13.5055\n",
            "Epoch 51 | Batch: 18 | Loss: 17.2486\n",
            "Epoch 51 | Batch: 19 | Loss: 15.9085\n",
            "Epoch 51 | Batch: 20 | Loss: 17.4130\n",
            "Epoch 51 | Batch: 21 | Loss: 21.4598\n",
            "Epoch 51 | Batch: 22 | Loss: 16.9305\n",
            "Epoch 51 | Batch: 23 | Loss: 16.9420\n",
            "Epoch 51 | Batch: 24 | Loss: 12.6512\n",
            "Epoch 52 | Batch: 1 | Loss: 16.5223\n",
            "Epoch 52 | Batch: 2 | Loss: 13.7574\n",
            "Epoch 52 | Batch: 3 | Loss: 15.1937\n",
            "Epoch 52 | Batch: 4 | Loss: 13.1285\n",
            "Epoch 52 | Batch: 5 | Loss: 14.3400\n",
            "Epoch 52 | Batch: 6 | Loss: 16.1335\n",
            "Epoch 52 | Batch: 7 | Loss: 20.8634\n",
            "Epoch 52 | Batch: 8 | Loss: 15.5915\n",
            "Epoch 52 | Batch: 9 | Loss: 14.1486\n",
            "Epoch 52 | Batch: 10 | Loss: 20.0791\n",
            "Epoch 52 | Batch: 11 | Loss: 17.9301\n",
            "Epoch 52 | Batch: 12 | Loss: 15.8679\n",
            "Epoch 52 | Batch: 13 | Loss: 12.6628\n",
            "Epoch 52 | Batch: 14 | Loss: 12.9538\n",
            "Epoch 52 | Batch: 15 | Loss: 17.6450\n",
            "Epoch 52 | Batch: 16 | Loss: 17.2024\n",
            "Epoch 52 | Batch: 17 | Loss: 11.2858\n",
            "Epoch 52 | Batch: 18 | Loss: 11.8673\n",
            "Epoch 52 | Batch: 19 | Loss: 19.8951\n",
            "Epoch 52 | Batch: 20 | Loss: 11.7644\n",
            "Epoch 52 | Batch: 21 | Loss: 20.0391\n",
            "Epoch 52 | Batch: 22 | Loss: 17.6486\n",
            "Epoch 52 | Batch: 23 | Loss: 12.7054\n",
            "Epoch 52 | Batch: 24 | Loss: 12.8731\n",
            "Epoch 53 | Batch: 1 | Loss: 15.2953\n",
            "Epoch 53 | Batch: 2 | Loss: 15.4380\n",
            "Epoch 53 | Batch: 3 | Loss: 20.3645\n",
            "Epoch 53 | Batch: 4 | Loss: 12.1755\n",
            "Epoch 53 | Batch: 5 | Loss: 13.5340\n",
            "Epoch 53 | Batch: 6 | Loss: 16.5506\n",
            "Epoch 53 | Batch: 7 | Loss: 15.7032\n",
            "Epoch 53 | Batch: 8 | Loss: 17.2448\n",
            "Epoch 53 | Batch: 9 | Loss: 16.7519\n",
            "Epoch 53 | Batch: 10 | Loss: 18.3635\n",
            "Epoch 53 | Batch: 11 | Loss: 18.2939\n",
            "Epoch 53 | Batch: 12 | Loss: 16.8797\n",
            "Epoch 53 | Batch: 13 | Loss: 18.0361\n",
            "Epoch 53 | Batch: 14 | Loss: 13.6144\n",
            "Epoch 53 | Batch: 15 | Loss: 12.8921\n",
            "Epoch 53 | Batch: 16 | Loss: 13.8523\n",
            "Epoch 53 | Batch: 17 | Loss: 15.1789\n",
            "Epoch 53 | Batch: 18 | Loss: 10.4476\n",
            "Epoch 53 | Batch: 19 | Loss: 20.1908\n",
            "Epoch 53 | Batch: 20 | Loss: 14.8429\n",
            "Epoch 53 | Batch: 21 | Loss: 12.7239\n",
            "Epoch 53 | Batch: 22 | Loss: 14.1450\n",
            "Epoch 53 | Batch: 23 | Loss: 12.9720\n",
            "Epoch 53 | Batch: 24 | Loss: 11.5133\n",
            "Epoch 54 | Batch: 1 | Loss: 14.3235\n",
            "Epoch 54 | Batch: 2 | Loss: 10.7104\n",
            "Epoch 54 | Batch: 3 | Loss: 18.9055\n",
            "Epoch 54 | Batch: 4 | Loss: 11.6398\n",
            "Epoch 54 | Batch: 5 | Loss: 14.7261\n",
            "Epoch 54 | Batch: 6 | Loss: 9.6140\n",
            "Epoch 54 | Batch: 7 | Loss: 20.3586\n",
            "Epoch 54 | Batch: 8 | Loss: 14.8257\n",
            "Epoch 54 | Batch: 9 | Loss: 15.4245\n",
            "Epoch 54 | Batch: 10 | Loss: 13.8320\n",
            "Epoch 54 | Batch: 11 | Loss: 11.6947\n",
            "Epoch 54 | Batch: 12 | Loss: 14.8456\n",
            "Epoch 54 | Batch: 13 | Loss: 18.9309\n",
            "Epoch 54 | Batch: 14 | Loss: 20.2055\n",
            "Epoch 54 | Batch: 15 | Loss: 13.7661\n",
            "Epoch 54 | Batch: 16 | Loss: 11.7663\n",
            "Epoch 54 | Batch: 17 | Loss: 19.7123\n",
            "Epoch 54 | Batch: 18 | Loss: 13.5117\n",
            "Epoch 54 | Batch: 19 | Loss: 13.1282\n",
            "Epoch 54 | Batch: 20 | Loss: 21.0479\n",
            "Epoch 54 | Batch: 21 | Loss: 16.4827\n",
            "Epoch 54 | Batch: 22 | Loss: 17.9592\n",
            "Epoch 54 | Batch: 23 | Loss: 15.6612\n",
            "Epoch 54 | Batch: 24 | Loss: 7.0540\n",
            "Epoch 55 | Batch: 1 | Loss: 15.2069\n",
            "Epoch 55 | Batch: 2 | Loss: 12.4971\n",
            "Epoch 55 | Batch: 3 | Loss: 20.8826\n",
            "Epoch 55 | Batch: 4 | Loss: 27.9797\n",
            "Epoch 55 | Batch: 5 | Loss: 12.5949\n",
            "Epoch 55 | Batch: 6 | Loss: 15.5829\n",
            "Epoch 55 | Batch: 7 | Loss: 15.2379\n",
            "Epoch 55 | Batch: 8 | Loss: 15.0297\n",
            "Epoch 55 | Batch: 9 | Loss: 15.5484\n",
            "Epoch 55 | Batch: 10 | Loss: 16.7250\n",
            "Epoch 55 | Batch: 11 | Loss: 14.5926\n",
            "Epoch 55 | Batch: 12 | Loss: 15.3173\n",
            "Epoch 55 | Batch: 13 | Loss: 13.5966\n",
            "Epoch 55 | Batch: 14 | Loss: 16.4624\n",
            "Epoch 55 | Batch: 15 | Loss: 15.8549\n",
            "Epoch 55 | Batch: 16 | Loss: 15.7070\n",
            "Epoch 55 | Batch: 17 | Loss: 11.8827\n",
            "Epoch 55 | Batch: 18 | Loss: 12.1828\n",
            "Epoch 55 | Batch: 19 | Loss: 12.1279\n",
            "Epoch 55 | Batch: 20 | Loss: 23.2809\n",
            "Epoch 55 | Batch: 21 | Loss: 19.1634\n",
            "Epoch 55 | Batch: 22 | Loss: 17.3642\n",
            "Epoch 55 | Batch: 23 | Loss: 15.1492\n",
            "Epoch 55 | Batch: 24 | Loss: 11.0739\n",
            "Epoch 56 | Batch: 1 | Loss: 16.9147\n",
            "Epoch 56 | Batch: 2 | Loss: 15.6864\n",
            "Epoch 56 | Batch: 3 | Loss: 16.2628\n",
            "Epoch 56 | Batch: 4 | Loss: 16.4798\n",
            "Epoch 56 | Batch: 5 | Loss: 19.7884\n",
            "Epoch 56 | Batch: 6 | Loss: 13.6141\n",
            "Epoch 56 | Batch: 7 | Loss: 13.3333\n",
            "Epoch 56 | Batch: 8 | Loss: 11.8858\n",
            "Epoch 56 | Batch: 9 | Loss: 16.2125\n",
            "Epoch 56 | Batch: 10 | Loss: 11.1459\n",
            "Epoch 56 | Batch: 11 | Loss: 11.2061\n",
            "Epoch 56 | Batch: 12 | Loss: 10.9275\n",
            "Epoch 56 | Batch: 13 | Loss: 20.3063\n",
            "Epoch 56 | Batch: 14 | Loss: 16.7059\n",
            "Epoch 56 | Batch: 15 | Loss: 17.1902\n",
            "Epoch 56 | Batch: 16 | Loss: 14.1731\n",
            "Epoch 56 | Batch: 17 | Loss: 19.2728\n",
            "Epoch 56 | Batch: 18 | Loss: 12.7335\n",
            "Epoch 56 | Batch: 19 | Loss: 20.7105\n",
            "Epoch 56 | Batch: 20 | Loss: 21.6981\n",
            "Epoch 56 | Batch: 21 | Loss: 12.5902\n",
            "Epoch 56 | Batch: 22 | Loss: 15.0380\n",
            "Epoch 56 | Batch: 23 | Loss: 17.5604\n",
            "Epoch 56 | Batch: 24 | Loss: 11.8168\n",
            "Epoch 57 | Batch: 1 | Loss: 9.9191\n",
            "Epoch 57 | Batch: 2 | Loss: 22.6508\n",
            "Epoch 57 | Batch: 3 | Loss: 23.6485\n",
            "Epoch 57 | Batch: 4 | Loss: 16.5813\n",
            "Epoch 57 | Batch: 5 | Loss: 12.0442\n",
            "Epoch 57 | Batch: 6 | Loss: 12.0714\n",
            "Epoch 57 | Batch: 7 | Loss: 10.5518\n",
            "Epoch 57 | Batch: 8 | Loss: 12.2470\n",
            "Epoch 57 | Batch: 9 | Loss: 16.3577\n",
            "Epoch 57 | Batch: 10 | Loss: 13.9226\n",
            "Epoch 57 | Batch: 11 | Loss: 17.2581\n",
            "Epoch 57 | Batch: 12 | Loss: 13.0473\n",
            "Epoch 57 | Batch: 13 | Loss: 7.6372\n",
            "Epoch 57 | Batch: 14 | Loss: 18.4698\n",
            "Epoch 57 | Batch: 15 | Loss: 13.4078\n",
            "Epoch 57 | Batch: 16 | Loss: 21.4295\n",
            "Epoch 57 | Batch: 17 | Loss: 15.2665\n",
            "Epoch 57 | Batch: 18 | Loss: 18.0313\n",
            "Epoch 57 | Batch: 19 | Loss: 11.8984\n",
            "Epoch 57 | Batch: 20 | Loss: 13.3543\n",
            "Epoch 57 | Batch: 21 | Loss: 14.4539\n",
            "Epoch 57 | Batch: 22 | Loss: 19.4201\n",
            "Epoch 57 | Batch: 23 | Loss: 16.3693\n",
            "Epoch 57 | Batch: 24 | Loss: 19.8746\n",
            "Epoch 58 | Batch: 1 | Loss: 15.6055\n",
            "Epoch 58 | Batch: 2 | Loss: 16.9726\n",
            "Epoch 58 | Batch: 3 | Loss: 13.6777\n",
            "Epoch 58 | Batch: 4 | Loss: 16.8810\n",
            "Epoch 58 | Batch: 5 | Loss: 13.4415\n",
            "Epoch 58 | Batch: 6 | Loss: 17.1602\n",
            "Epoch 58 | Batch: 7 | Loss: 12.2069\n",
            "Epoch 58 | Batch: 8 | Loss: 12.9652\n",
            "Epoch 58 | Batch: 9 | Loss: 16.7453\n",
            "Epoch 58 | Batch: 10 | Loss: 18.8306\n",
            "Epoch 58 | Batch: 11 | Loss: 11.5906\n",
            "Epoch 58 | Batch: 12 | Loss: 17.5233\n",
            "Epoch 58 | Batch: 13 | Loss: 21.2237\n",
            "Epoch 58 | Batch: 14 | Loss: 13.6053\n",
            "Epoch 58 | Batch: 15 | Loss: 17.2837\n",
            "Epoch 58 | Batch: 16 | Loss: 17.6570\n",
            "Epoch 58 | Batch: 17 | Loss: 16.7479\n",
            "Epoch 58 | Batch: 18 | Loss: 10.9684\n",
            "Epoch 58 | Batch: 19 | Loss: 13.8653\n",
            "Epoch 58 | Batch: 20 | Loss: 14.0876\n",
            "Epoch 58 | Batch: 21 | Loss: 12.1730\n",
            "Epoch 58 | Batch: 22 | Loss: 12.9631\n",
            "Epoch 58 | Batch: 23 | Loss: 16.4916\n",
            "Epoch 58 | Batch: 24 | Loss: 9.3758\n",
            "Epoch 59 | Batch: 1 | Loss: 18.5303\n",
            "Epoch 59 | Batch: 2 | Loss: 16.5345\n",
            "Epoch 59 | Batch: 3 | Loss: 15.0873\n",
            "Epoch 59 | Batch: 4 | Loss: 18.9804\n",
            "Epoch 59 | Batch: 5 | Loss: 15.0914\n",
            "Epoch 59 | Batch: 6 | Loss: 17.5521\n",
            "Epoch 59 | Batch: 7 | Loss: 13.8356\n",
            "Epoch 59 | Batch: 8 | Loss: 14.2287\n",
            "Epoch 59 | Batch: 9 | Loss: 16.9436\n",
            "Epoch 59 | Batch: 10 | Loss: 13.0256\n",
            "Epoch 59 | Batch: 11 | Loss: 8.2461\n",
            "Epoch 59 | Batch: 12 | Loss: 11.5181\n",
            "Epoch 59 | Batch: 13 | Loss: 11.6468\n",
            "Epoch 59 | Batch: 14 | Loss: 11.8468\n",
            "Epoch 59 | Batch: 15 | Loss: 17.0560\n",
            "Epoch 59 | Batch: 16 | Loss: 19.9246\n",
            "Epoch 59 | Batch: 17 | Loss: 18.3834\n",
            "Epoch 59 | Batch: 18 | Loss: 18.2320\n",
            "Epoch 59 | Batch: 19 | Loss: 13.8147\n",
            "Epoch 59 | Batch: 20 | Loss: 15.8424\n",
            "Epoch 59 | Batch: 21 | Loss: 15.5014\n",
            "Epoch 59 | Batch: 22 | Loss: 16.4249\n",
            "Epoch 59 | Batch: 23 | Loss: 17.0338\n",
            "Epoch 59 | Batch: 24 | Loss: 10.1626\n",
            "Epoch 60 | Batch: 1 | Loss: 14.1475\n",
            "Epoch 60 | Batch: 2 | Loss: 12.6964\n",
            "Epoch 60 | Batch: 3 | Loss: 18.8161\n",
            "Epoch 60 | Batch: 4 | Loss: 10.7916\n",
            "Epoch 60 | Batch: 5 | Loss: 9.7461\n",
            "Epoch 60 | Batch: 6 | Loss: 17.8063\n",
            "Epoch 60 | Batch: 7 | Loss: 13.1556\n",
            "Epoch 60 | Batch: 8 | Loss: 20.2654\n",
            "Epoch 60 | Batch: 9 | Loss: 12.6973\n",
            "Epoch 60 | Batch: 10 | Loss: 14.4238\n",
            "Epoch 60 | Batch: 11 | Loss: 14.2380\n",
            "Epoch 60 | Batch: 12 | Loss: 14.9208\n",
            "Epoch 60 | Batch: 13 | Loss: 17.4891\n",
            "Epoch 60 | Batch: 14 | Loss: 10.8865\n",
            "Epoch 60 | Batch: 15 | Loss: 16.0962\n",
            "Epoch 60 | Batch: 16 | Loss: 15.6499\n",
            "Epoch 60 | Batch: 17 | Loss: 20.7057\n",
            "Epoch 60 | Batch: 18 | Loss: 12.4179\n",
            "Epoch 60 | Batch: 19 | Loss: 10.6104\n",
            "Epoch 60 | Batch: 20 | Loss: 16.5278\n",
            "Epoch 60 | Batch: 21 | Loss: 17.1906\n",
            "Epoch 60 | Batch: 22 | Loss: 21.6933\n",
            "Epoch 60 | Batch: 23 | Loss: 24.6908\n",
            "Epoch 60 | Batch: 24 | Loss: 11.3541\n",
            "Epoch 61 | Batch: 1 | Loss: 11.9480\n",
            "Epoch 61 | Batch: 2 | Loss: 16.6741\n",
            "Epoch 61 | Batch: 3 | Loss: 15.6470\n",
            "Epoch 61 | Batch: 4 | Loss: 15.5430\n",
            "Epoch 61 | Batch: 5 | Loss: 11.9266\n",
            "Epoch 61 | Batch: 6 | Loss: 17.7524\n",
            "Epoch 61 | Batch: 7 | Loss: 16.2162\n",
            "Epoch 61 | Batch: 8 | Loss: 10.4167\n",
            "Epoch 61 | Batch: 9 | Loss: 14.2466\n",
            "Epoch 61 | Batch: 10 | Loss: 13.2839\n",
            "Epoch 61 | Batch: 11 | Loss: 11.4049\n",
            "Epoch 61 | Batch: 12 | Loss: 20.1345\n",
            "Epoch 61 | Batch: 13 | Loss: 18.7018\n",
            "Epoch 61 | Batch: 14 | Loss: 14.5799\n",
            "Epoch 61 | Batch: 15 | Loss: 15.3580\n",
            "Epoch 61 | Batch: 16 | Loss: 15.7725\n",
            "Epoch 61 | Batch: 17 | Loss: 10.4914\n",
            "Epoch 61 | Batch: 18 | Loss: 16.2544\n",
            "Epoch 61 | Batch: 19 | Loss: 13.9899\n",
            "Epoch 61 | Batch: 20 | Loss: 13.4308\n",
            "Epoch 61 | Batch: 21 | Loss: 14.4566\n",
            "Epoch 61 | Batch: 22 | Loss: 16.2595\n",
            "Epoch 61 | Batch: 23 | Loss: 18.5899\n",
            "Epoch 61 | Batch: 24 | Loss: 13.1602\n",
            "Epoch 62 | Batch: 1 | Loss: 11.5085\n",
            "Epoch 62 | Batch: 2 | Loss: 10.4729\n",
            "Epoch 62 | Batch: 3 | Loss: 21.2125\n",
            "Epoch 62 | Batch: 4 | Loss: 16.3391\n",
            "Epoch 62 | Batch: 5 | Loss: 13.2846\n",
            "Epoch 62 | Batch: 6 | Loss: 9.1904\n",
            "Epoch 62 | Batch: 7 | Loss: 17.5842\n",
            "Epoch 62 | Batch: 8 | Loss: 13.4282\n",
            "Epoch 62 | Batch: 9 | Loss: 12.1214\n",
            "Epoch 62 | Batch: 10 | Loss: 19.1725\n",
            "Epoch 62 | Batch: 11 | Loss: 16.8473\n",
            "Epoch 62 | Batch: 12 | Loss: 17.1674\n",
            "Epoch 62 | Batch: 13 | Loss: 12.5909\n",
            "Epoch 62 | Batch: 14 | Loss: 15.3124\n",
            "Epoch 62 | Batch: 15 | Loss: 13.3667\n",
            "Epoch 62 | Batch: 16 | Loss: 13.5967\n",
            "Epoch 62 | Batch: 17 | Loss: 15.0461\n",
            "Epoch 62 | Batch: 18 | Loss: 18.5451\n",
            "Epoch 62 | Batch: 19 | Loss: 18.9143\n",
            "Epoch 62 | Batch: 20 | Loss: 18.6773\n",
            "Epoch 62 | Batch: 21 | Loss: 15.5190\n",
            "Epoch 62 | Batch: 22 | Loss: 12.3267\n",
            "Epoch 62 | Batch: 23 | Loss: 20.2736\n",
            "Epoch 62 | Batch: 24 | Loss: 9.7322\n",
            "Epoch 63 | Batch: 1 | Loss: 15.6631\n",
            "Epoch 63 | Batch: 2 | Loss: 16.1742\n",
            "Epoch 63 | Batch: 3 | Loss: 13.5605\n",
            "Epoch 63 | Batch: 4 | Loss: 15.2803\n",
            "Epoch 63 | Batch: 5 | Loss: 13.7492\n",
            "Epoch 63 | Batch: 6 | Loss: 14.9806\n",
            "Epoch 63 | Batch: 7 | Loss: 17.4377\n",
            "Epoch 63 | Batch: 8 | Loss: 16.3059\n",
            "Epoch 63 | Batch: 9 | Loss: 11.8049\n",
            "Epoch 63 | Batch: 10 | Loss: 14.3379\n",
            "Epoch 63 | Batch: 11 | Loss: 12.4058\n",
            "Epoch 63 | Batch: 12 | Loss: 17.0264\n",
            "Epoch 63 | Batch: 13 | Loss: 15.6883\n",
            "Epoch 63 | Batch: 14 | Loss: 13.9465\n",
            "Epoch 63 | Batch: 15 | Loss: 12.5100\n",
            "Epoch 63 | Batch: 16 | Loss: 18.7040\n",
            "Epoch 63 | Batch: 17 | Loss: 20.2653\n",
            "Epoch 63 | Batch: 18 | Loss: 16.1326\n",
            "Epoch 63 | Batch: 19 | Loss: 11.8886\n",
            "Epoch 63 | Batch: 20 | Loss: 25.8335\n",
            "Epoch 63 | Batch: 21 | Loss: 17.2231\n",
            "Epoch 63 | Batch: 22 | Loss: 10.3066\n",
            "Epoch 63 | Batch: 23 | Loss: 15.8831\n",
            "Epoch 63 | Batch: 24 | Loss: 12.7221\n",
            "Epoch 64 | Batch: 1 | Loss: 14.4109\n",
            "Epoch 64 | Batch: 2 | Loss: 11.3422\n",
            "Epoch 64 | Batch: 3 | Loss: 14.8719\n",
            "Epoch 64 | Batch: 4 | Loss: 18.2568\n",
            "Epoch 64 | Batch: 5 | Loss: 15.5744\n",
            "Epoch 64 | Batch: 6 | Loss: 18.2673\n",
            "Epoch 64 | Batch: 7 | Loss: 17.0635\n",
            "Epoch 64 | Batch: 8 | Loss: 18.3177\n",
            "Epoch 64 | Batch: 9 | Loss: 15.0178\n",
            "Epoch 64 | Batch: 10 | Loss: 17.0960\n",
            "Epoch 64 | Batch: 11 | Loss: 18.3815\n",
            "Epoch 64 | Batch: 12 | Loss: 16.1936\n",
            "Epoch 64 | Batch: 13 | Loss: 14.9177\n",
            "Epoch 64 | Batch: 14 | Loss: 15.7664\n",
            "Epoch 64 | Batch: 15 | Loss: 12.2727\n",
            "Epoch 64 | Batch: 16 | Loss: 11.3966\n",
            "Epoch 64 | Batch: 17 | Loss: 7.5315\n",
            "Epoch 64 | Batch: 18 | Loss: 13.5147\n",
            "Epoch 64 | Batch: 19 | Loss: 15.5423\n",
            "Epoch 64 | Batch: 20 | Loss: 21.1874\n",
            "Epoch 64 | Batch: 21 | Loss: 9.6720\n",
            "Epoch 64 | Batch: 22 | Loss: 15.7767\n",
            "Epoch 64 | Batch: 23 | Loss: 14.8563\n",
            "Epoch 64 | Batch: 24 | Loss: 11.9800\n",
            "Epoch 65 | Batch: 1 | Loss: 15.4477\n",
            "Epoch 65 | Batch: 2 | Loss: 12.0440\n",
            "Epoch 65 | Batch: 3 | Loss: 9.5207\n",
            "Epoch 65 | Batch: 4 | Loss: 14.4988\n",
            "Epoch 65 | Batch: 5 | Loss: 12.2532\n",
            "Epoch 65 | Batch: 6 | Loss: 10.7286\n",
            "Epoch 65 | Batch: 7 | Loss: 8.8884\n",
            "Epoch 65 | Batch: 8 | Loss: 19.8020\n",
            "Epoch 65 | Batch: 9 | Loss: 15.4906\n",
            "Epoch 65 | Batch: 10 | Loss: 16.5980\n",
            "Epoch 65 | Batch: 11 | Loss: 15.1567\n",
            "Epoch 65 | Batch: 12 | Loss: 21.2188\n",
            "Epoch 65 | Batch: 13 | Loss: 16.2717\n",
            "Epoch 65 | Batch: 14 | Loss: 15.1704\n",
            "Epoch 65 | Batch: 15 | Loss: 18.1889\n",
            "Epoch 65 | Batch: 16 | Loss: 16.9624\n",
            "Epoch 65 | Batch: 17 | Loss: 14.6290\n",
            "Epoch 65 | Batch: 18 | Loss: 17.1036\n",
            "Epoch 65 | Batch: 19 | Loss: 14.8297\n",
            "Epoch 65 | Batch: 20 | Loss: 12.4898\n",
            "Epoch 65 | Batch: 21 | Loss: 12.2428\n",
            "Epoch 65 | Batch: 22 | Loss: 14.9977\n",
            "Epoch 65 | Batch: 23 | Loss: 15.8208\n",
            "Epoch 65 | Batch: 24 | Loss: 18.9471\n",
            "Epoch 66 | Batch: 1 | Loss: 17.9625\n",
            "Epoch 66 | Batch: 2 | Loss: 18.4448\n",
            "Epoch 66 | Batch: 3 | Loss: 15.7390\n",
            "Epoch 66 | Batch: 4 | Loss: 13.2390\n",
            "Epoch 66 | Batch: 5 | Loss: 15.2261\n",
            "Epoch 66 | Batch: 6 | Loss: 15.1651\n",
            "Epoch 66 | Batch: 7 | Loss: 12.3351\n",
            "Epoch 66 | Batch: 8 | Loss: 15.7280\n",
            "Epoch 66 | Batch: 9 | Loss: 20.5172\n",
            "Epoch 66 | Batch: 10 | Loss: 12.3606\n",
            "Epoch 66 | Batch: 11 | Loss: 9.6978\n",
            "Epoch 66 | Batch: 12 | Loss: 15.8160\n",
            "Epoch 66 | Batch: 13 | Loss: 20.7402\n",
            "Epoch 66 | Batch: 14 | Loss: 13.4519\n",
            "Epoch 66 | Batch: 15 | Loss: 18.0420\n",
            "Epoch 66 | Batch: 16 | Loss: 16.3407\n",
            "Epoch 66 | Batch: 17 | Loss: 12.9261\n",
            "Epoch 66 | Batch: 18 | Loss: 17.7746\n",
            "Epoch 66 | Batch: 19 | Loss: 18.6110\n",
            "Epoch 66 | Batch: 20 | Loss: 14.1292\n",
            "Epoch 66 | Batch: 21 | Loss: 18.4278\n",
            "Epoch 66 | Batch: 22 | Loss: 16.9698\n",
            "Epoch 66 | Batch: 23 | Loss: 12.1554\n",
            "Epoch 66 | Batch: 24 | Loss: 10.6433\n",
            "Epoch 67 | Batch: 1 | Loss: 17.4519\n",
            "Epoch 67 | Batch: 2 | Loss: 15.1686\n",
            "Epoch 67 | Batch: 3 | Loss: 10.2017\n",
            "Epoch 67 | Batch: 4 | Loss: 14.6252\n",
            "Epoch 67 | Batch: 5 | Loss: 14.1505\n",
            "Epoch 67 | Batch: 6 | Loss: 19.5179\n",
            "Epoch 67 | Batch: 7 | Loss: 11.3653\n",
            "Epoch 67 | Batch: 8 | Loss: 15.7682\n",
            "Epoch 67 | Batch: 9 | Loss: 16.4960\n",
            "Epoch 67 | Batch: 10 | Loss: 9.1219\n",
            "Epoch 67 | Batch: 11 | Loss: 17.5657\n",
            "Epoch 67 | Batch: 12 | Loss: 16.3856\n",
            "Epoch 67 | Batch: 13 | Loss: 13.2582\n",
            "Epoch 67 | Batch: 14 | Loss: 11.5046\n",
            "Epoch 67 | Batch: 15 | Loss: 19.5627\n",
            "Epoch 67 | Batch: 16 | Loss: 19.2441\n",
            "Epoch 67 | Batch: 17 | Loss: 14.9603\n",
            "Epoch 67 | Batch: 18 | Loss: 16.3587\n",
            "Epoch 67 | Batch: 19 | Loss: 17.8452\n",
            "Epoch 67 | Batch: 20 | Loss: 17.6709\n",
            "Epoch 67 | Batch: 21 | Loss: 13.7345\n",
            "Epoch 67 | Batch: 22 | Loss: 15.9347\n",
            "Epoch 67 | Batch: 23 | Loss: 15.6009\n",
            "Epoch 67 | Batch: 24 | Loss: 7.7313\n",
            "Epoch 68 | Batch: 1 | Loss: 14.1767\n",
            "Epoch 68 | Batch: 2 | Loss: 18.0752\n",
            "Epoch 68 | Batch: 3 | Loss: 17.4087\n",
            "Epoch 68 | Batch: 4 | Loss: 13.1023\n",
            "Epoch 68 | Batch: 5 | Loss: 13.1963\n",
            "Epoch 68 | Batch: 6 | Loss: 15.1232\n",
            "Epoch 68 | Batch: 7 | Loss: 14.6161\n",
            "Epoch 68 | Batch: 8 | Loss: 15.7193\n",
            "Epoch 68 | Batch: 9 | Loss: 13.0495\n",
            "Epoch 68 | Batch: 10 | Loss: 15.1048\n",
            "Epoch 68 | Batch: 11 | Loss: 14.1641\n",
            "Epoch 68 | Batch: 12 | Loss: 22.2566\n",
            "Epoch 68 | Batch: 13 | Loss: 16.2613\n",
            "Epoch 68 | Batch: 14 | Loss: 6.6948\n",
            "Epoch 68 | Batch: 15 | Loss: 12.7628\n",
            "Epoch 68 | Batch: 16 | Loss: 20.4080\n",
            "Epoch 68 | Batch: 17 | Loss: 17.0260\n",
            "Epoch 68 | Batch: 18 | Loss: 15.8319\n",
            "Epoch 68 | Batch: 19 | Loss: 13.4305\n",
            "Epoch 68 | Batch: 20 | Loss: 22.1462\n",
            "Epoch 68 | Batch: 21 | Loss: 16.5739\n",
            "Epoch 68 | Batch: 22 | Loss: 16.3593\n",
            "Epoch 68 | Batch: 23 | Loss: 14.0583\n",
            "Epoch 68 | Batch: 24 | Loss: 8.9484\n",
            "Epoch 69 | Batch: 1 | Loss: 14.7085\n",
            "Epoch 69 | Batch: 2 | Loss: 16.6557\n",
            "Epoch 69 | Batch: 3 | Loss: 13.0417\n",
            "Epoch 69 | Batch: 4 | Loss: 16.1630\n",
            "Epoch 69 | Batch: 5 | Loss: 18.1966\n",
            "Epoch 69 | Batch: 6 | Loss: 14.9801\n",
            "Epoch 69 | Batch: 7 | Loss: 18.4635\n",
            "Epoch 69 | Batch: 8 | Loss: 15.0673\n",
            "Epoch 69 | Batch: 9 | Loss: 13.1150\n",
            "Epoch 69 | Batch: 10 | Loss: 20.0992\n",
            "Epoch 69 | Batch: 11 | Loss: 14.6460\n",
            "Epoch 69 | Batch: 12 | Loss: 14.6133\n",
            "Epoch 69 | Batch: 13 | Loss: 13.7838\n",
            "Epoch 69 | Batch: 14 | Loss: 16.1941\n",
            "Epoch 69 | Batch: 15 | Loss: 12.2228\n",
            "Epoch 69 | Batch: 16 | Loss: 13.8759\n",
            "Epoch 69 | Batch: 17 | Loss: 16.6080\n",
            "Epoch 69 | Batch: 18 | Loss: 15.4025\n",
            "Epoch 69 | Batch: 19 | Loss: 13.5585\n",
            "Epoch 69 | Batch: 20 | Loss: 12.1940\n",
            "Epoch 69 | Batch: 21 | Loss: 16.0058\n",
            "Epoch 69 | Batch: 22 | Loss: 16.7644\n",
            "Epoch 69 | Batch: 23 | Loss: 18.6485\n",
            "Epoch 69 | Batch: 24 | Loss: 9.2461\n",
            "Epoch 70 | Batch: 1 | Loss: 13.2165\n",
            "Epoch 70 | Batch: 2 | Loss: 12.7867\n",
            "Epoch 70 | Batch: 3 | Loss: 14.0489\n",
            "Epoch 70 | Batch: 4 | Loss: 19.0828\n",
            "Epoch 70 | Batch: 5 | Loss: 17.7381\n",
            "Epoch 70 | Batch: 6 | Loss: 10.9795\n",
            "Epoch 70 | Batch: 7 | Loss: 14.3126\n",
            "Epoch 70 | Batch: 8 | Loss: 13.3576\n",
            "Epoch 70 | Batch: 9 | Loss: 17.0356\n",
            "Epoch 70 | Batch: 10 | Loss: 15.0545\n",
            "Epoch 70 | Batch: 11 | Loss: 16.8920\n",
            "Epoch 70 | Batch: 12 | Loss: 15.9350\n",
            "Epoch 70 | Batch: 13 | Loss: 14.4115\n",
            "Epoch 70 | Batch: 14 | Loss: 13.8119\n",
            "Epoch 70 | Batch: 15 | Loss: 16.6086\n",
            "Epoch 70 | Batch: 16 | Loss: 18.1592\n",
            "Epoch 70 | Batch: 17 | Loss: 16.0521\n",
            "Epoch 70 | Batch: 18 | Loss: 10.6157\n",
            "Epoch 70 | Batch: 19 | Loss: 19.7700\n",
            "Epoch 70 | Batch: 20 | Loss: 17.0282\n",
            "Epoch 70 | Batch: 21 | Loss: 13.3920\n",
            "Epoch 70 | Batch: 22 | Loss: 15.5582\n",
            "Epoch 70 | Batch: 23 | Loss: 10.0343\n",
            "Epoch 70 | Batch: 24 | Loss: 9.7922\n",
            "Epoch 71 | Batch: 1 | Loss: 21.6464\n",
            "Epoch 71 | Batch: 2 | Loss: 17.2602\n",
            "Epoch 71 | Batch: 3 | Loss: 11.4192\n",
            "Epoch 71 | Batch: 4 | Loss: 14.9460\n",
            "Epoch 71 | Batch: 5 | Loss: 14.7543\n",
            "Epoch 71 | Batch: 6 | Loss: 13.9237\n",
            "Epoch 71 | Batch: 7 | Loss: 14.0411\n",
            "Epoch 71 | Batch: 8 | Loss: 14.4445\n",
            "Epoch 71 | Batch: 9 | Loss: 20.9365\n",
            "Epoch 71 | Batch: 10 | Loss: 20.2640\n",
            "Epoch 71 | Batch: 11 | Loss: 13.4084\n",
            "Epoch 71 | Batch: 12 | Loss: 14.3390\n",
            "Epoch 71 | Batch: 13 | Loss: 18.2448\n",
            "Epoch 71 | Batch: 14 | Loss: 14.1931\n",
            "Epoch 71 | Batch: 15 | Loss: 15.8923\n",
            "Epoch 71 | Batch: 16 | Loss: 13.4685\n",
            "Epoch 71 | Batch: 17 | Loss: 16.6780\n",
            "Epoch 71 | Batch: 18 | Loss: 14.5431\n",
            "Epoch 71 | Batch: 19 | Loss: 17.2656\n",
            "Epoch 71 | Batch: 20 | Loss: 14.8602\n",
            "Epoch 71 | Batch: 21 | Loss: 11.9544\n",
            "Epoch 71 | Batch: 22 | Loss: 14.7942\n",
            "Epoch 71 | Batch: 23 | Loss: 17.3811\n",
            "Epoch 71 | Batch: 24 | Loss: 7.6093\n",
            "Epoch 72 | Batch: 1 | Loss: 11.5266\n",
            "Epoch 72 | Batch: 2 | Loss: 16.4287\n",
            "Epoch 72 | Batch: 3 | Loss: 18.6298\n",
            "Epoch 72 | Batch: 4 | Loss: 17.5059\n",
            "Epoch 72 | Batch: 5 | Loss: 16.2666\n",
            "Epoch 72 | Batch: 6 | Loss: 16.3776\n",
            "Epoch 72 | Batch: 7 | Loss: 15.7597\n",
            "Epoch 72 | Batch: 8 | Loss: 11.6122\n",
            "Epoch 72 | Batch: 9 | Loss: 14.7942\n",
            "Epoch 72 | Batch: 10 | Loss: 11.5734\n",
            "Epoch 72 | Batch: 11 | Loss: 14.8672\n",
            "Epoch 72 | Batch: 12 | Loss: 15.9181\n",
            "Epoch 72 | Batch: 13 | Loss: 16.5683\n",
            "Epoch 72 | Batch: 14 | Loss: 14.9801\n",
            "Epoch 72 | Batch: 15 | Loss: 15.2464\n",
            "Epoch 72 | Batch: 16 | Loss: 13.4073\n",
            "Epoch 72 | Batch: 17 | Loss: 10.5980\n",
            "Epoch 72 | Batch: 18 | Loss: 11.8723\n",
            "Epoch 72 | Batch: 19 | Loss: 13.2308\n",
            "Epoch 72 | Batch: 20 | Loss: 18.3645\n",
            "Epoch 72 | Batch: 21 | Loss: 17.3654\n",
            "Epoch 72 | Batch: 22 | Loss: 17.2790\n",
            "Epoch 72 | Batch: 23 | Loss: 23.2875\n",
            "Epoch 72 | Batch: 24 | Loss: 10.2018\n",
            "Epoch 73 | Batch: 1 | Loss: 19.5431\n",
            "Epoch 73 | Batch: 2 | Loss: 16.8799\n",
            "Epoch 73 | Batch: 3 | Loss: 12.6922\n",
            "Epoch 73 | Batch: 4 | Loss: 12.6540\n",
            "Epoch 73 | Batch: 5 | Loss: 13.0066\n",
            "Epoch 73 | Batch: 6 | Loss: 19.9333\n",
            "Epoch 73 | Batch: 7 | Loss: 14.0629\n",
            "Epoch 73 | Batch: 8 | Loss: 15.1543\n",
            "Epoch 73 | Batch: 9 | Loss: 13.5746\n",
            "Epoch 73 | Batch: 10 | Loss: 12.0548\n",
            "Epoch 73 | Batch: 11 | Loss: 18.3577\n",
            "Epoch 73 | Batch: 12 | Loss: 12.4618\n",
            "Epoch 73 | Batch: 13 | Loss: 15.0036\n",
            "Epoch 73 | Batch: 14 | Loss: 9.2531\n",
            "Epoch 73 | Batch: 15 | Loss: 12.4783\n",
            "Epoch 73 | Batch: 16 | Loss: 14.6681\n",
            "Epoch 73 | Batch: 17 | Loss: 14.2277\n",
            "Epoch 73 | Batch: 18 | Loss: 14.8445\n",
            "Epoch 73 | Batch: 19 | Loss: 16.9862\n",
            "Epoch 73 | Batch: 20 | Loss: 16.9982\n",
            "Epoch 73 | Batch: 21 | Loss: 13.9706\n",
            "Epoch 73 | Batch: 22 | Loss: 19.4785\n",
            "Epoch 73 | Batch: 23 | Loss: 17.5245\n",
            "Epoch 73 | Batch: 24 | Loss: 10.5905\n",
            "Epoch 74 | Batch: 1 | Loss: 15.3146\n",
            "Epoch 74 | Batch: 2 | Loss: 18.0110\n",
            "Epoch 74 | Batch: 3 | Loss: 13.3371\n",
            "Epoch 74 | Batch: 4 | Loss: 20.0695\n",
            "Epoch 74 | Batch: 5 | Loss: 18.9363\n",
            "Epoch 74 | Batch: 6 | Loss: 12.8626\n",
            "Epoch 74 | Batch: 7 | Loss: 16.9165\n",
            "Epoch 74 | Batch: 8 | Loss: 20.6321\n",
            "Epoch 74 | Batch: 9 | Loss: 17.8841\n",
            "Epoch 74 | Batch: 10 | Loss: 15.4103\n",
            "Epoch 74 | Batch: 11 | Loss: 13.3369\n",
            "Epoch 74 | Batch: 12 | Loss: 11.6977\n",
            "Epoch 74 | Batch: 13 | Loss: 14.5569\n",
            "Epoch 74 | Batch: 14 | Loss: 8.3317\n",
            "Epoch 74 | Batch: 15 | Loss: 10.4622\n",
            "Epoch 74 | Batch: 16 | Loss: 15.5283\n",
            "Epoch 74 | Batch: 17 | Loss: 10.8470\n",
            "Epoch 74 | Batch: 18 | Loss: 14.1082\n",
            "Epoch 74 | Batch: 19 | Loss: 18.5381\n",
            "Epoch 74 | Batch: 20 | Loss: 11.1021\n",
            "Epoch 74 | Batch: 21 | Loss: 16.4294\n",
            "Epoch 74 | Batch: 22 | Loss: 18.2622\n",
            "Epoch 74 | Batch: 23 | Loss: 7.8320\n",
            "Epoch 74 | Batch: 24 | Loss: 12.5194\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-56715ec95ad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m       \u001b[0;31m# get the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m                 \u001b[0;31m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_join_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njl2IFOYKkUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCEVG-2nKkXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfQIH8ODKkZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5WciYowKkb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBPgswFWKke1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yajmAIpKkhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLCBbLsmKklV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}